{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, defaultdict\n",
    "import glob\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "import gezi\n",
    "from gezi import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../input/feed_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_ID = -1\n",
    "d = d.fillna(NAN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = None\n",
    "vocab_names = [\n",
    "                'user', 'doc',\n",
    "                'author', 'singer', 'song',\n",
    "                'key', 'tag', 'word', 'char'\n",
    "              ]\n",
    "vocabs = {}\n",
    "\n",
    "for vocab_name in vocab_names:\n",
    "  vocab_file =  f'../input/{vocab_name}_vocab.txt'\n",
    "  # if not doc then mask as UNK for rare words, tags, keys..\n",
    "  min_count = None if vocab_name == 'doc' else MIN_COUNT\n",
    "#   min_count = MIN_COUNT if vocab_name in ['word', 'char'] else None\n",
    "  vocab = gezi.Vocab(vocab_file, min_count=min_count)\n",
    "  vocabs[vocab_name] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_emb = np.load('../input/tag_norm_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 128\n",
    "embs = [[0] * EMB_DIM] * vocabs['doc'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd52b687bef41628bcd57b70950f4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feed_info-manual_tag:   0%|          | 0/106444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(d.itertuples(), total=len(d), desc='feed_info-manual_tag'):\n",
    "  row = row._asdict()\n",
    "  docid = vocabs['doc'].id(int(row['feedid']))\n",
    "  manual_tags = str(row['manual_tag_list']).split(';')\n",
    "  manual_tags_embs = []\n",
    "  for tag in manual_tags:\n",
    "    if tag == 'nan' or tag == str(NAN_ID):\n",
    "      continue\n",
    "    else:\n",
    "      manual_tags_embs.append(tag_emb[vocabs['tag'].id(int(tag))])\n",
    "  if manual_tags_embs:\n",
    "    manual_tags_embs = np.asarray(manual_tags_embs)\n",
    "    embs[docid] = list(np.mean(manual_tags_embs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106446, 128)\n"
     ]
    }
   ],
   "source": [
    "embs = np.asarray(embs)\n",
    "print(embs.shape)\n",
    "np.save('../input/manual_tag_emb.npy', embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106446, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.07993865, -0.03124299,  0.12596407, ...,  0.03842705,\n",
       "         0.06031519, -0.0859609 ],\n",
       "       ...,\n",
       "       [-0.06670049, -0.0714559 ,  0.21368824, ...,  0.01563483,\n",
       "        -0.07410432, -0.16339597],\n",
       "       [-0.06670049, -0.0714559 ,  0.21368824, ...,  0.01563483,\n",
       "        -0.07410432, -0.16339597],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../input/doc_embs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 128\n",
    "embs = [[0] * EMB_DIM] * vocabs['doc'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f390a6e34214693a598da903462bac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feed_info-machine_tag:   0%|          | 0/106444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(d.itertuples(), total=len(d), desc='feed_info-machine_tag'):\n",
    "  row = row._asdict()\n",
    "  docid = vocabs['doc'].id(int(row['feedid']))\n",
    "  machine_tags = str(row['machine_tag_list']).split(';')\n",
    "  machine_tags_embs = []\n",
    "  for tag in machine_tags:\n",
    "    if tag == 'nan' or tag == str(NAN_ID):\n",
    "      continue\n",
    "    else:\n",
    "      x = tag.split()\n",
    "      tag, prob = int(x[0]), float(x[1])\n",
    "      machine_tags_embs.append(prob * tag_emb[vocabs['tag'].id(int(tag))])\n",
    "  if machine_tags_embs:\n",
    "    machine_tags_embs = np.asarray(machine_tags_embs)\n",
    "    embs[docid] = list(np.mean(machine_tags_embs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106446, 128)\n"
     ]
    }
   ],
   "source": [
    "embs = np.asarray(embs)\n",
    "print(embs.shape)\n",
    "np.save('../input/machine_tag_emb.npy', embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_emb = np.load('../input/key_norm_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 128\n",
    "embs = [[0] * EMB_DIM] * vocabs['doc'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cd7328272145cfae6162373f24e2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feed_info-manual_key:   0%|          | 0/106444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(d.itertuples(), total=len(d), desc='feed_info-manual_key'):\n",
    "  row = row._asdict()\n",
    "  docid = vocabs['doc'].id(int(row['feedid']))\n",
    "  manual_keys = str(row['manual_keyword_list']).split(';')\n",
    "  manual_keys_embs = []\n",
    "  for key in manual_keys:\n",
    "    if key == 'nan' or key == str(NAN_ID):\n",
    "      continue\n",
    "    else:\n",
    "      manual_keys_embs.append(key_emb[vocabs['key'].id(int(key))])\n",
    "  if manual_keys_embs:\n",
    "    manual_keys_embs = np.asarray(manual_keys_embs)\n",
    "    embs[docid] = list(np.mean(manual_keys_embs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106446, 128)\n"
     ]
    }
   ],
   "source": [
    "embs = np.asarray(embs)\n",
    "print(embs.shape)\n",
    "np.save('../input/manual_key_emb.npy', embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 128\n",
    "embs = [[0] * EMB_DIM] * vocabs['doc'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696798c07f7b4a0db7b5346c8ce0a1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "feed_info-machine_key:   0%|          | 0/106444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(d.itertuples(), total=len(d), desc='feed_info-machine_key'):\n",
    "  row = row._asdict()\n",
    "  docid = vocabs['doc'].id(int(row['feedid']))\n",
    "  machine_keys = str(row['machine_keyword_list']).split(';')\n",
    "  machine_keys_embs = []\n",
    "  for key in machine_keys:\n",
    "    if key == 'nan' or key == str(NAN_ID):\n",
    "      continue\n",
    "    else:\n",
    "      machine_keys_embs.append(key_emb[vocabs['key'].id(int(key))])\n",
    "  if machine_keys_embs:\n",
    "    machine_keys_embs = np.asarray(machine_keys_embs)\n",
    "    embs[docid] = list(np.mean(machine_keys_embs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106446, 128)\n"
     ]
    }
   ],
   "source": [
    "embs = np.asarray(embs)\n",
    "print(embs.shape)\n",
    "np.save('../input/machine_key_emb.npy', embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = [\n",
    "    np.load('../input/manual_tag_emb.npy'),\n",
    "    np.load('../input/manual_key_emb.npy'),\n",
    "    np.load('../input/machine_tag_emb.npy'),\n",
    "    np.load('../input/machine_key_emb.npy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../input/docs_emb.npy', embs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = np.concatenate(embs, -1)\n",
    "print(embs.shape)\n",
    "np.save('../input/docs_emb.npy', embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
