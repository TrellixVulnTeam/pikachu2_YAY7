{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 05:51:25.371949: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys,os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "from multiprocessing import Pool, Manager, cpu_count \n",
    "import pymp\n",
    "import qgrid\n",
    "import glob\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"jupyterlab\"\n",
    "import gezi\n",
    "from gezi import tqdm, line\n",
    "tqdm.pandas()\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = f'../working/offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 35\n",
    "V2 = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df(root, pattern='metrics'):\n",
    "  dfs= []\n",
    "  pattern = f'{root}/*/pairwise/*/{pattern}.csv'\n",
    "  files = glob.glob(pattern)\n",
    "  print(files)\n",
    "#   if not files:\n",
    "#     return None\n",
    "#   files = sorted(files, key=lambda x: os.path.getmtime(x))\n",
    "#   ps = min(len(files), cpu_count())\n",
    "#   with pymp.Parallel(ps) as p:\n",
    "# #     for i in tqdm(p.range(len(files)),desc='gen_df'):\n",
    "#     for i in p.range(len(files)):\n",
    "#       file = files[i]\n",
    "#       if not gezi.non_empty(file):\n",
    "#         continue\n",
    "#       df = pd.read_csv(file)\n",
    "#       try:\n",
    "#         v = int(os.path.basename(os.path.dirname(os.path.dirname(file))))\n",
    "#       except Exception:\n",
    "#         continue\n",
    "#       if v < V:\n",
    "#         continue\n",
    "# #       if v < V2 and len(df) <  4:\n",
    "# #         continue\n",
    "#       model_name = os.path.basename(os.path.dirname(file))\n",
    "#       v_ = model_name.split('-')[0]\n",
    "#       if v_.isdigit():\n",
    "#         continue\n",
    "#       df['model'] = f'{v}-{model_name}'\n",
    "#       df['mtime'] = os.path.getmtime(file)\n",
    "#       df['ctime'] = os.path.getctime(file)\n",
    "#       df['step'] = [x + 1 for x in range(len(df))]\n",
    "#       dfs.append(df)\n",
    "  df = pd.concat(list(dfs))\n",
    "  df = df.reset_index()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gen_df(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.groupby('model')['epoch'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = ['train_loss', 'val_loss', 'lr']\n",
    "# line(history, keys, x='step', color='model', smoothing=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(metric, df=df_):\n",
    "  res = None\n",
    "  try:\n",
    "    # res = df.groupby(['step', 'model'])[metric] \\\n",
    "    #   .aggregate(np.mean).reset_index() \\\n",
    "    #   .pivot('step', 'model', metric)\n",
    "    line(df, metric, x='step', color='model')\n",
    "  except Exception:\n",
    "    pass\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(metric, df=df_, num=30):\n",
    "  try:\n",
    "    d = df[['model', 'step', metric]].sort_values([metric], ascending=False).reset_index(drop=True)\n",
    "    # display(d.head(num))\n",
    "  except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_pandas(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank('spearmanr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('spearmanr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('spearmanr', df_[df_.model.str.contains('now.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show('spearmanr', df_[df_.model.str.contains('ft.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import tensorflow as tf\n",
    " negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "        true_classes=[[1, 2 ,3]],  # class that should be sampled as 'positive'\n",
    "        num_true=3,  # each positive skip-gram has 1 positive context class\n",
    "        num_sampled=5,  # number of negative context words to sample\n",
    "        unique=True,  # all the negative samples should be unique\n",
    "        range_max=1000 - 2,  # pick index of the samples from [0, vocab_size]\n",
    "        seed=1024,  # seed for reproducibility\n",
    "        name=\"negative_sampling\"  # name of this operation\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sampling_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e1511501be64c09e2f1eb58c3220ebc9ce84b491d308a480caed250bbb4af51"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
