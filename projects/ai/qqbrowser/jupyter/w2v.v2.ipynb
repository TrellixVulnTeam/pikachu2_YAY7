{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, defaultdict\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "import gezi\n",
    "from gezi import tqdm\n",
    "tqdm.pandas()\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import jieba"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pip install numba --upgrade  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class MonitorCallback(CallbackAny2Vec):\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.epoch = 1\n",
    "    self.timer = gezi.Timer()\n",
    "    \n",
    "  def on_epoch_end(self, model):\n",
    "    # TODO 为什么打印train loss一直是0\n",
    "    print('name:', self.name, 'epoch:', self.epoch, \"model loss:\", model.get_latest_training_loss(), f'elapsed minutes: {self.timer.elapsed_minutes():.2f}')  # print loss\n",
    "    self.epoch += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocab_names = [\n",
    "                'tag',\n",
    "                'word',\n",
    "              ]\n",
    "vocabs = {}\n",
    "for vocab_name in vocab_names:\n",
    "  vocab_file =  f'../input/{vocab_name}_vocab.txt'\n",
    "  if vocab_name != 'word':\n",
    "    vocab = gezi.Vocab(vocab_file)\n",
    "  else:\n",
    "    vocab = gezi.Vocab(vocab_file, 200)\n",
    "  vocabs[vocab_name] = vocab\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocabs['tag']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d = pd.read_csv('../input/info/infos.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.head(30)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def gen_w2v(window=32, min_count=1, emb_dim=256):\n",
    "  sentences = []\n",
    "  for row in tqdm(d.itertuples(), total=len(d)):\n",
    "    row = row._asdict()\n",
    "    l = [row['category_id'], '[SEP1]', row['cat'], '[SEP2]', *(str(row['tag_id']).split(',')), '[CLS]', *jieba.cut(str(row['title'])), '[SEP]', *jieba.cut(str(row['asr_text'])), '[SEP]']\n",
    "    sentences.append(l)\n",
    "  ic(len(sentences))\n",
    "  name = 'word'\n",
    "  monitor = gezi.MonitorCallback(name) \n",
    "  w2v = Word2Vec(sentences, vector_size=emb_dim, window=window, min_count=min_count, sg=1, workers=mp.cpu_count(), epochs=10, callbacks=[monitor])\n",
    "  ofile = f'../input/w2v/jieba/{emb_dim}/{name}.pkl'\n",
    "  gezi.try_mkdir(os.path.dirname(ofile))\n",
    "  for name in vocabs:\n",
    "    vocab = vocabs[name]\n",
    "    # emb = np.zeros([vocab.size(), emb_dim])\n",
    "    emb = np.random.uniform(-0.05, 0.05,(vocab.size(), emb_dim))\n",
    "    for i in range(vocab.size()):\n",
    "      word = vocab.key(i) \n",
    "      if word in w2v.wv:\n",
    "        emb[i] = w2v.wv[word]\n",
    "    ofile = f'../input/w2v/jieba/{emb_dim}/{name}.npy'\n",
    "    np.save(ofile, emb)\n",
    "  \n",
    "  return w2v"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gen_w2v(emb_dim=256)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gen_w2v(emb_dim=512)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emb_dims = [256, 512]\n",
    "for emb_dim in emb_dims:\n",
    "  w2v = gezi.read_pickle( f'../input/w2v/jieba/{emb_dim}/word.pkl')\n",
    "  for name in vocabs:\n",
    "    print(name)\n",
    "    vocab = vocabs[name]\n",
    "    # emb = np.zeros([vocab.size(), emb_dim])\n",
    "    emb = np.random.uniform(-0.05, 0.05,(vocab.size(), emb_dim))\n",
    "    for i in range(vocab.size()):\n",
    "      word = vocab.key(i) \n",
    "      if word in w2v.wv:\n",
    "        emb[i] = w2v.wv[word]\n",
    "    ofile = f'../input/w2v/jieba/{emb_dim}/{name}.npy'\n",
    "    np.save(ofile, emb)\n",
    "    print(emb)\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70ae7f01e3b5fb553a7d054aea81f4c71c9c83bb3068e07c284cf675fd217cad"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}