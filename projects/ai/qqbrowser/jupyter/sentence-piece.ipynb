{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, defaultdict\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "import gezi\n",
    "from gezi import tqdm\n",
    "tqdm.pandas()\n",
    "import sentencepiece as spm\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../input/info/infos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2046fad0cd4e63990aaad2414dd574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1138154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('../input/corpus.txt', 'w') as f:\n",
    "  for row in tqdm(d.itertuples(), total=len(d)):\n",
    "    print(row.title, file=f)\n",
    "    print(row.asr_text, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../input/corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: ../input/sp10w\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 100000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: SEP0\n",
      "  user_defined_symbols: SEP1\n",
      "  user_defined_symbols: SEP2\n",
      "  user_defined_symbols: SEP3\n",
      "  user_defined_symbols: SEP4\n",
      "  user_defined_symbols: SEP5\n",
      "  user_defined_symbols: SEP6\n",
      "  user_defined_symbols: SEP7\n",
      "  user_defined_symbols: SEP8\n",
      "  user_defined_symbols: SEP9\n",
      "  user_defined_symbols: SEP10\n",
      "  user_defined_symbols: SEP11\n",
      "  user_defined_symbols: SEP12\n",
      "  user_defined_symbols: SEP13\n",
      "  user_defined_symbols: SEP14\n",
      "  user_defined_symbols: SEP15\n",
      "  user_defined_symbols: SEP16\n",
      "  user_defined_symbols: SEP17\n",
      "  user_defined_symbols: SEP18\n",
      "  user_defined_symbols: SEP19\n",
      "  user_defined_symbols: SEP20\n",
      "  user_defined_symbols: SEP21\n",
      "  user_defined_symbols: SEP22\n",
      "  user_defined_symbols: SEP23\n",
      "  user_defined_symbols: SEP24\n",
      "  user_defined_symbols: SEP25\n",
      "  user_defined_symbols: SEP26\n",
      "  user_defined_symbols: SEP27\n",
      "  user_defined_symbols: SEP28\n",
      "  user_defined_symbols: SEP29\n",
      "  user_defined_symbols: SEP30\n",
      "  user_defined_symbols: SEP31\n",
      "  user_defined_symbols: SEP32\n",
      "  user_defined_symbols: SEP33\n",
      "  user_defined_symbols: SEP34\n",
      "  user_defined_symbols: SEP35\n",
      "  user_defined_symbols: SEP36\n",
      "  user_defined_symbols: SEP37\n",
      "  user_defined_symbols: SEP38\n",
      "  user_defined_symbols: SEP39\n",
      "  user_defined_symbols: SEP40\n",
      "  user_defined_symbols: SEP41\n",
      "  user_defined_symbols: SEP42\n",
      "  user_defined_symbols: SEP43\n",
      "  user_defined_symbols: SEP44\n",
      "  user_defined_symbols: SEP45\n",
      "  user_defined_symbols: SEP46\n",
      "  user_defined_symbols: SEP47\n",
      "  user_defined_symbols: SEP48\n",
      "  user_defined_symbols: SEP49\n",
      "  user_defined_symbols: SEP50\n",
      "  user_defined_symbols: SEP51\n",
      "  user_defined_symbols: SEP52\n",
      "  user_defined_symbols: SEP53\n",
      "  user_defined_symbols: SEP54\n",
      "  user_defined_symbols: SEP55\n",
      "  user_defined_symbols: SEP56\n",
      "  user_defined_symbols: SEP57\n",
      "  user_defined_symbols: SEP58\n",
      "  user_defined_symbols: SEP59\n",
      "  user_defined_symbols: SEP60\n",
      "  user_defined_symbols: SEP61\n",
      "  user_defined_symbols: SEP62\n",
      "  user_defined_symbols: SEP63\n",
      "  user_defined_symbols: SEP64\n",
      "  user_defined_symbols: SEP65\n",
      "  user_defined_symbols: SEP66\n",
      "  user_defined_symbols: SEP67\n",
      "  user_defined_symbols: SEP68\n",
      "  user_defined_symbols: SEP69\n",
      "  user_defined_symbols: SEP70\n",
      "  user_defined_symbols: SEP71\n",
      "  user_defined_symbols: SEP72\n",
      "  user_defined_symbols: SEP73\n",
      "  user_defined_symbols: SEP74\n",
      "  user_defined_symbols: SEP75\n",
      "  user_defined_symbols: SEP76\n",
      "  user_defined_symbols: SEP77\n",
      "  user_defined_symbols: SEP78\n",
      "  user_defined_symbols: SEP79\n",
      "  user_defined_symbols: SEP80\n",
      "  user_defined_symbols: SEP81\n",
      "  user_defined_symbols: SEP82\n",
      "  user_defined_symbols: SEP83\n",
      "  user_defined_symbols: SEP84\n",
      "  user_defined_symbols: SEP85\n",
      "  user_defined_symbols: SEP86\n",
      "  user_defined_symbols: SEP87\n",
      "  user_defined_symbols: SEP88\n",
      "  user_defined_symbols: SEP89\n",
      "  user_defined_symbols: SEP90\n",
      "  user_defined_symbols: SEP91\n",
      "  user_defined_symbols: SEP92\n",
      "  user_defined_symbols: SEP93\n",
      "  user_defined_symbols: SEP94\n",
      "  user_defined_symbols: SEP95\n",
      "  user_defined_symbols: SEP96\n",
      "  user_defined_symbols: SEP97\n",
      "  user_defined_symbols: SEP98\n",
      "  user_defined_symbols: SEP99\n",
      "  user_defined_symbols: SEP100\n",
      "  user_defined_symbols: SEP101\n",
      "  user_defined_symbols: SEP102\n",
      "  user_defined_symbols: SEP103\n",
      "  user_defined_symbols: SEP104\n",
      "  user_defined_symbols: SEP105\n",
      "  user_defined_symbols: SEP106\n",
      "  user_defined_symbols: SEP107\n",
      "  user_defined_symbols: SEP108\n",
      "  user_defined_symbols: SEP109\n",
      "  user_defined_symbols: SEP110\n",
      "  user_defined_symbols: SEP111\n",
      "  user_defined_symbols: SEP112\n",
      "  user_defined_symbols: SEP113\n",
      "  user_defined_symbols: SEP114\n",
      "  user_defined_symbols: SEP115\n",
      "  user_defined_symbols: SEP116\n",
      "  user_defined_symbols: SEP117\n",
      "  user_defined_symbols: SEP118\n",
      "  user_defined_symbols: SEP119\n",
      "  user_defined_symbols: SEP120\n",
      "  user_defined_symbols: SEP121\n",
      "  user_defined_symbols: SEP122\n",
      "  user_defined_symbols: SEP123\n",
      "  user_defined_symbols: SEP124\n",
      "  user_defined_symbols: SEP125\n",
      "  user_defined_symbols: SEP126\n",
      "  user_defined_symbols: SEP127\n",
      "  user_defined_symbols: SEP128\n",
      "  user_defined_symbols: SEP129\n",
      "  user_defined_symbols: SEP130\n",
      "  user_defined_symbols: SEP131\n",
      "  user_defined_symbols: SEP132\n",
      "  user_defined_symbols: SEP133\n",
      "  user_defined_symbols: SEP134\n",
      "  user_defined_symbols: SEP135\n",
      "  user_defined_symbols: SEP136\n",
      "  user_defined_symbols: SEP137\n",
      "  user_defined_symbols: SEP138\n",
      "  user_defined_symbols: SEP139\n",
      "  user_defined_symbols: SEP140\n",
      "  user_defined_symbols: SEP141\n",
      "  user_defined_symbols: SEP142\n",
      "  user_defined_symbols: SEP143\n",
      "  user_defined_symbols: SEP144\n",
      "  user_defined_symbols: SEP145\n",
      "  user_defined_symbols: SEP146\n",
      "  user_defined_symbols: SEP147\n",
      "  user_defined_symbols: SEP148\n",
      "  user_defined_symbols: SEP149\n",
      "  user_defined_symbols: SEP150\n",
      "  user_defined_symbols: SEP151\n",
      "  user_defined_symbols: SEP152\n",
      "  user_defined_symbols: SEP153\n",
      "  user_defined_symbols: SEP154\n",
      "  user_defined_symbols: SEP155\n",
      "  user_defined_symbols: SEP156\n",
      "  user_defined_symbols: SEP157\n",
      "  user_defined_symbols: SEP158\n",
      "  user_defined_symbols: SEP159\n",
      "  user_defined_symbols: SEP160\n",
      "  user_defined_symbols: SEP161\n",
      "  user_defined_symbols: SEP162\n",
      "  user_defined_symbols: SEP163\n",
      "  user_defined_symbols: SEP164\n",
      "  user_defined_symbols: SEP165\n",
      "  user_defined_symbols: SEP166\n",
      "  user_defined_symbols: SEP167\n",
      "  user_defined_symbols: SEP168\n",
      "  user_defined_symbols: SEP169\n",
      "  user_defined_symbols: SEP170\n",
      "  user_defined_symbols: SEP171\n",
      "  user_defined_symbols: SEP172\n",
      "  user_defined_symbols: SEP173\n",
      "  user_defined_symbols: SEP174\n",
      "  user_defined_symbols: SEP175\n",
      "  user_defined_symbols: SEP176\n",
      "  user_defined_symbols: SEP177\n",
      "  user_defined_symbols: SEP178\n",
      "  user_defined_symbols: SEP179\n",
      "  user_defined_symbols: SEP180\n",
      "  user_defined_symbols: SEP181\n",
      "  user_defined_symbols: SEP182\n",
      "  user_defined_symbols: SEP183\n",
      "  user_defined_symbols: SEP184\n",
      "  user_defined_symbols: SEP185\n",
      "  user_defined_symbols: SEP186\n",
      "  user_defined_symbols: SEP187\n",
      "  user_defined_symbols: SEP188\n",
      "  user_defined_symbols: SEP189\n",
      "  user_defined_symbols: SEP190\n",
      "  user_defined_symbols: SEP191\n",
      "  user_defined_symbols: SEP192\n",
      "  user_defined_symbols: SEP193\n",
      "  user_defined_symbols: SEP194\n",
      "  user_defined_symbols: SEP195\n",
      "  user_defined_symbols: SEP196\n",
      "  user_defined_symbols: SEP197\n",
      "  user_defined_symbols: SEP198\n",
      "  user_defined_symbols: SEP199\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ../input/corpus.txt\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(356) LOG(WARNING) Found too long line (6336 > 4192).\n",
      "trainer_interface.cc(358) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(359) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (2276293), which may slow down training.\n",
      "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2276293 sentences\n",
      "trainer_interface.cc(391) LOG(INFO) Skipped 15 too long sentences.\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP0\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP1\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP2\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP3\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP4\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP5\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP6\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP7\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP8\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP9\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP10\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP11\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP12\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP13\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP14\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP15\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP16\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP17\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP18\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP19\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP20\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP21\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP22\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP23\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP24\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP25\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP26\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP27\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP28\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP29\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP30\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP31\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP32\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP33\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP34\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP35\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP36\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP37\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP38\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP39\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP40\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP41\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP42\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP43\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP44\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP45\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP46\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP47\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP48\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP49\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP50\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP51\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP52\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP53\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP54\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP55\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP56\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP57\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP58\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP59\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP60\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP61\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP62\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP63\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP64\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP65\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP66\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP67\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP68\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP69\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP70\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP71\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP72\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP73\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP74\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP75\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP76\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP77\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP78\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP79\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP80\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP81\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP82\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP83\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP84\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP85\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP86\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP87\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP88\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP89\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP90\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP91\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP92\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP93\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP94\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP95\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP96\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP97\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP98\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP99\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP100\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP101\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP102\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP103\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP104\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP105\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP106\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP107\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP108\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP109\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP110\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP111\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP112\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP113\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP114\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP115\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP116\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP117\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP118\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP119\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP120\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP121\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP122\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP123\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP124\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP125\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP126\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP127\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP128\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP129\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP130\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP131\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP132\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP133\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP134\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP135\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP136\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP137\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP138\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP139\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP140\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP141\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP142\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP143\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP144\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP145\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP146\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP147\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP148\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP149\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP150\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP151\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP152\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP153\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP154\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP155\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP156\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP157\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP158\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP159\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP160\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP161\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP162\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP163\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP164\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP165\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP166\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP167\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP168\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP169\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP170\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP171\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP172\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP173\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP174\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP175\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP176\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP177\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP178\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP179\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP180\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP181\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP182\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP183\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP184\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP185\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP186\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP187\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP188\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP189\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP190\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP191\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP192\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP193\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP194\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP195\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP196\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP197\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP198\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: SEP199\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=70406794\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=3998\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2276293 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 1000000 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2276293\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 2039322\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 2039322 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=799001 obj=133.779 num_tokens=31448925 num_tokens/piece=39.3603\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=712210 obj=123.417 num_tokens=31654172 num_tokens/piece=44.445\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=534061 obj=123.424 num_tokens=31972892 num_tokens/piece=59.8675\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=533785 obj=123.246 num_tokens=32043963 num_tokens/piece=60.0316\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=400336 obj=123.756 num_tokens=32524773 num_tokens/piece=81.2437\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=400332 obj=123.51 num_tokens=32561468 num_tokens/piece=81.3362\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=300247 obj=124.454 num_tokens=33262083 num_tokens/piece=110.782\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=300243 obj=124.085 num_tokens=33289060 num_tokens/piece=110.874\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=225182 obj=125.377 num_tokens=34078694 num_tokens/piece=151.338\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=225182 obj=124.936 num_tokens=34106306 num_tokens/piece=151.461\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=168886 obj=126.506 num_tokens=34942464 num_tokens/piece=206.9\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=168886 obj=126.05 num_tokens=34970538 num_tokens/piece=207.066\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=126664 obj=127.848 num_tokens=35857478 num_tokens/piece=283.091\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=126664 obj=127.385 num_tokens=35883127 num_tokens/piece=283.294\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=110000 obj=128.313 num_tokens=36344599 num_tokens/piece=330.405\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=110000 obj=128.081 num_tokens=36373129 num_tokens/piece=330.665\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: ../input/sp10w.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ../input/sp10w.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input='../input/corpus.txt', model_prefix='../input/sp10w', vocab_size=100000, user_defined_symbols=[f'SEP{i}' for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22330, 63717, 5246, 205, 7545, 5246, 205, 7506, 205, 89475, 75999]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='../input/sp10w.model')\n",
    "sp.encode('This is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'日日SEP98SEP99'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.decode([22130,101,102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我只不过跳了跳舞，结果光子实在太狠了\n",
      "[277, 6889, 7785, 670, 204, 408, 28086, 1394, 8143]\n",
      "['▁我', '只不过', '跳了', '跳舞', ',', '结果', '光子', '实在', '太狠了']\n"
     ]
    }
   ],
   "source": [
    "for line in open('../input/corpus.txt'):\n",
    "  line = line.strip()\n",
    "  print(line)\n",
    "  print(sp.encode(line))\n",
    "  print(sp.encode(line, out_type=str))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = gezi.Vocab('../input/sp10w.vocab', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[277, 6889]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode('我只不过')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.id('我')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28086"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.id('光子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEP98'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.key(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_names = [\n",
    "                'tag',\n",
    "                'word',\n",
    "              ]\n",
    "vocabs = {}\n",
    "for vocab_name in vocab_names:\n",
    "  if vocab_name != 'word':\n",
    "    vocab_file =  f'../input/{vocab_name}_vocab.txt'\n",
    "    vocab = gezi.Vocab(vocab_file)\n",
    "  else:\n",
    "    vocab_file = '../input/sp10w.vocab'\n",
    "    vocab = gezi.Vocab(vocab_file, 0)\n",
    "  vocabs[vocab_name] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>subcat</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>title</th>\n",
       "      <th>asr_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8181862433864400302</td>\n",
       "      <td>10804</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>55848798,800002360,593341,55744355,55859481,55...</td>\n",
       "      <td>我只不过跳了跳舞，结果光子实在太狠了</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4155641279071878522</td>\n",
       "      <td>10401</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>286226,101389,800000950,9504442,9820430</td>\n",
       "      <td>这么可爱的小姐姐，太搞怪了</td>\n",
       "      <td>邢飞真的是太能搞怪了，跟粉丝的速度一点都不装特别的，真就是喜欢这么正的女孩，你们是不是跟你一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6281338907679991214</td>\n",
       "      <td>10501</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>56080717,4093463,41614380,224444,101461,560840...</td>\n",
       "      <td>最近超级火的歌曲《冬眠》，美女唱得很不赖，绝对是实力派</td>\n",
       "      <td>你听。热车吗？你听着他说着你的。只上了赌注你。拍女生。啊。都要。的总结到位深。你替他掩饰着粽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8506122561779211694</td>\n",
       "      <td>11604</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>530228,3326413</td>\n",
       "      <td>下地干农活无意间拍下这一幕，这是什么东西，吓我一跳</td>\n",
       "      <td>一样。会落实。隆隆天空。给个反应。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4696077578276769146</td>\n",
       "      <td>10012</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>101334,102376,800000171,10115859</td>\n",
       "      <td>和女儿们一块玩游戏，把她俩给骗了，她们却玩的很开心</td>\n",
       "      <td>你想。样子。认真在。让魔王魔王。是谁。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  category_id  cat  subcat  \\\n",
       "0  8181862433864400302        10804  108       4   \n",
       "1  4155641279071878522        10401  104       1   \n",
       "2  6281338907679991214        10501  105       1   \n",
       "3  8506122561779211694        11604  116       4   \n",
       "4  4696077578276769146        10012  100      12   \n",
       "\n",
       "                                              tag_id  \\\n",
       "0  55848798,800002360,593341,55744355,55859481,55...   \n",
       "1            286226,101389,800000950,9504442,9820430   \n",
       "2  56080717,4093463,41614380,224444,101461,560840...   \n",
       "3                                     530228,3326413   \n",
       "4                   101334,102376,800000171,10115859   \n",
       "\n",
       "                         title  \\\n",
       "0           我只不过跳了跳舞，结果光子实在太狠了   \n",
       "1                这么可爱的小姐姐，太搞怪了   \n",
       "2  最近超级火的歌曲《冬眠》，美女唱得很不赖，绝对是实力派   \n",
       "3    下地干农活无意间拍下这一幕，这是什么东西，吓我一跳   \n",
       "4    和女儿们一块玩游戏，把她俩给骗了，她们却玩的很开心   \n",
       "\n",
       "                                            asr_text  \n",
       "0                                                NaN  \n",
       "1  邢飞真的是太能搞怪了，跟粉丝的速度一点都不装特别的，真就是喜欢这么正的女孩，你们是不是跟你一...  \n",
       "2  你听。热车吗？你听着他说着你的。只上了赌注你。拍女生。啊。都要。的总结到位深。你替他掩饰着粽...  \n",
       "3                                  一样。会落实。隆隆天空。给个反应。  \n",
       "4                                你想。样子。认真在。让魔王魔王。是谁。  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26172a78d34d4b87a485bc4ef2a5c255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1138154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_words = []\n",
    "asr_words = []\n",
    "for row in tqdm(d.itertuples(), total=len(d)):\n",
    "  title_words.append(len(sp.encode(row.title)))\n",
    "  asr_words.append(len(sp.encode(str(row.asr_text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['title_words'] = title_words\n",
    "d['asr_words'] = asr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.138154e+06\n",
       "mean     9.539984e+00\n",
       "std      4.032122e+00\n",
       "min      1.000000e+00\n",
       "50%      9.000000e+00\n",
       "90%      1.500000e+01\n",
       "99%      1.900000e+01\n",
       "99.9%    2.400000e+01\n",
       "max      4.200000e+01\n",
       "Name: title_words, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.title_words.describe([.5,.9,.99,.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.138154e+06\n",
       "mean     2.367692e+01\n",
       "std      2.940315e+01\n",
       "min      1.000000e+00\n",
       "50%      1.400000e+01\n",
       "90%      5.700000e+01\n",
       "99%      1.420000e+02\n",
       "99.9%    2.090000e+02\n",
       "max      1.984000e+03\n",
       "Name: asr_words, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.asr_words.describe([.5,.9,.99,.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_w2v(window=32, min_count=1, emb_dim=256):\n",
    "  sentences = []\n",
    "  for row in tqdm(d.itertuples(), total=len(d)):\n",
    "    row = row._asdict()\n",
    "    l = ['[CLS]', *sp.encode(str(row['title']), out_type=str), '[SEP]', *sp.encode(str(row['asr_text']), out_type=str), '[SEP]']\n",
    "    sentences.append(l)\n",
    "  ic(len(sentences))\n",
    "  name = 'word'\n",
    "  monitor = gezi.MonitorCallback(name) \n",
    "  w2v = Word2Vec(sentences, vector_size=emb_dim, window=window, min_count=min_count, sg=1, workers=mp.cpu_count(), epochs=10, callbacks=[monitor])\n",
    "  ofile = f'../input/w2v/sp/{emb_dim}/{name}.pkl'\n",
    "  gezi.try_mkdir(os.path.dirname(ofile))\n",
    "  gezi.save_pickle(w2v, ofile)\n",
    "  for name in vocabs:\n",
    "    vocab = vocabs[name]\n",
    "    # emb = np.zeros([vocab.size(), emb_dim])\n",
    "    emb = np.random.uniform(-0.05, 0.05,(vocab.size(), emb_dim))\n",
    "    for i in range(vocab.size()):\n",
    "      word = vocab.key(i) \n",
    "      if word in w2v.wv:\n",
    "        emb[i] = w2v.wv[word]\n",
    "    ofile = f'../input/w2v/sp/{emb_dim}/{name}.npy'\n",
    "    np.save(ofile, emb)\n",
    "  \n",
    "  return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_w2v(emb_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_w2v(emb_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73041/2637649227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_w2v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "gen_w2v(emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_w2v(emb_dim=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_w2v(emb_dim=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78547d9276e46459ce0371753bc91a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1138154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 2606645293.py:7 in gen_w2v()- len(sentences): 1138154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: word epoch: 1 model loss: 0.0 elapsed minutes: 24.27\n",
      "name: word epoch: 2 model loss: 0.0 elapsed minutes: 28.84\n",
      "name: word epoch: 3 model loss: 0.0 elapsed minutes: 28.59\n",
      "name: word epoch: 4 model loss: 0.0 elapsed minutes: 28.83\n",
      "name: word epoch: 5 model loss: 0.0 elapsed minutes: 26.66\n",
      "name: word epoch: 6 model loss: 0.0 elapsed minutes: 25.17\n",
      "name: word epoch: 7 model loss: 0.0 elapsed minutes: 24.44\n",
      "name: word epoch: 8 model loss: 0.0 elapsed minutes: 24.06\n",
      "name: word epoch: 9 model loss: 0.0 elapsed minutes: 23.99\n"
     ]
    }
   ],
   "source": [
    "gen_w2v(emb_dim=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ea47313c94383bf8f680c96aa3342ec5666a2ae764c7d77e71df945692dda57"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
