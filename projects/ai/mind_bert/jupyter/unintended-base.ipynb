{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-multi\t\t\t\t\t  tfrecords\r\n",
      "huggingface\t\t\t\t\t  tf-xlm-roberta-base\r\n",
      "jigsaw-multilingual-toxic-comment-classification  tf-xlm-roberta-large\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../input/tfrecords'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os  \n",
    "import traceback\n",
    "\n",
    "RECORDS_PATH = '../input/tfrecords'\n",
    "\n",
    "if os.path.exists('/kaggle'):\n",
    "  sys.path.append('/kaggle/input/gezi-melt/utils/utils')\n",
    "  sys.path.append('/kaggle/input/official')\n",
    "  from kaggle_datasets import KaggleDatasets\n",
    "  try:\n",
    "    RECORDS_PATH = KaggleDatasets().get_gcs_path('toxic-multi-tfrecords') + '/tfrecords/tfrecords'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "  except Exception:\n",
    "    print(traceback.format_exc())\n",
    "    RECORDS_PATH = '../input/toxic-multi-tfrecords/tfrecords/tfrecords'\n",
    "    pass\n",
    "!ls ../input\n",
    "RECORDS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import official\n",
    "import gezi\n",
    "import melt\n",
    "import lele\n",
    "import husky\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from absl import app, flags\n",
    "FLAGS = flags.FLAGS\n",
    "try:\n",
    "    flags.DEFINE_string('model', None, '')\n",
    "    flags.DEFINE_bool('multi_head', False, '')\n",
    "    flags.DEFINE_string('pretrained', '../input/tf-xlm-roberta-large', '')\n",
    "    flags.DEFINE_string('pretrained2', None, '')\n",
    "    flags.DEFINE_integer('max_len', None, 'xlm 192 bert 128')\n",
    "    flags.DEFINE_bool('freeze_pretrained', False, '')\n",
    "    flags.DEFINE_bool('valid_en', False, '')\n",
    "    flags.DEFINE_alias('ve', 'valid_en')\n",
    "    flags.DEFINE_bool('test_en', None, '')\n",
    "    flags.DEFINE_bool('use_lang', False, '')\n",
    "    flags.DEFINE_bool('use_mlp', False, '')\n",
    "    flags.DEFINE_bool('use_src', False, '')\n",
    "    flags.DEFINE_bool('use_trans', False, '')\n",
    "    flags.DEFINE_string('task', 'toxic', '')\n",
    "except Exception:\n",
    "    pass\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags\n",
    "argv=['']\n",
    "FLAGS(argv)\n",
    "mark='xlm'\n",
    "FLAGS.train_input=f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train'\n",
    "FLAGS.valid_input=f'{RECORDS_PATH}/{mark}/validation'\n",
    "FLAGS.test_input=f'{RECORDS_PATH}/{mark}/test'\n",
    "FLAGS.valid_interval_steps=0\n",
    "FLAGS.verbose=1 \n",
    "FLAGS.num_epochs=1\n",
    "FLAGS.keras=1 \n",
    "FLAGS.buffer_size=2048\n",
    "FLAGS.learning_rate=3e-5 \n",
    "FLAGS.min_learning_rate=0.\n",
    "# FLAGS.opt_epsilon=1e-8 \n",
    "FLAGS.optimizer='bert-adamw'\n",
    "# FLAGS.optimizer='adam'\n",
    "FLAGS.metrics=['acc', 'auc'] \n",
    "FLAGS.test_names=['id', 'toxic']\n",
    "FLAGS.valid_interval_epochs=0.1\n",
    "FLAGS.test_interval_epochs=1.\n",
    "FLAGS.num_gpus=8\n",
    "FLAGS.cache=0\n",
    "FLAGS.model_dir='../working/exps/unintended'\n",
    "# FLAGS.ckpt_dir='../input/single-unintended'\n",
    "FLAGS.multi_head=0\n",
    "FLAGS.batch_parse=1\n",
    "FLAGS.save_model=1\n",
    "# FLAGS.pretrained = '../input/tf-xlm-roberta-large/'\n",
    "FLAGS.pretrained = '../input/tf-xlm-roberta-base/'\n",
    "FLAGS.batch_size=16 if 'large' in FLAGS.pretrained else 32\n",
    "FLAGS.debug=0\n",
    "FLAGS.sparse_to_dense=1 \n",
    "FLAGS.padding_idx=1 \n",
    "# FLAGS.buckets=190,350 \n",
    "FLAGS.buckets=[]\n",
    "FLAGS.batch_size=32 \n",
    "# FLAGS.batch_sizes=32,16,8 if not 'large' in FLAGS.pretrained else 16,8,4\n",
    "FLAGS.batch_sizes=[]\n",
    "# FLAGS.length_key='input_word_ids'\n",
    "FLAGS.max_len=192\n",
    "FLAGS.do_test=0\n",
    "\n",
    "toxic_types = ['severe_toxic', 'obscene', 'identity_hate', 'threat', 'insult']\n",
    "langs = ['en', 'es', 'it', 'tr', 'fr', 'pt', 'ru']\n",
    "srcs = ['unintended', 'toxic', 'test']\n",
    "\n",
    "BERT_GCS_PATH_SAVEDMODEL = '../input/bert-multi/bert_multi_from_tfhub'\n",
    "RECORDS_GCS_PATH = '../input/tfrecords'\n",
    "\n",
    "def init():\n",
    "  # if FLAGS.mode == 'valid' or FLAGS.mode == 'test':\n",
    "  #   FLAGS.gpus = 1\n",
    "  if FLAGS.valid_en:\n",
    "    if FLAGS.test_en is None:\n",
    "      FLAGS.test_en = True\n",
    "    FLAGS.valid_input = FLAGS.valid_input.replace('validation', 'validation-en')\n",
    "    FLAGS.train_input = FLAGS.train_input.replace('validation', 'validation-en')\n",
    "  if FLAGS.test_en:\n",
    "    FLAGS.test_input = FLAGS.test_input.replace('test', 'test-en')\n",
    "  if 'bylang' in FLAGS.valid_input:\n",
    "    if FLAGS.folds is not None:\n",
    "      FLAGS.folds = 3\n",
    "  \n",
    "  if FLAGS.max_len:\n",
    "    FLAGS.keras_loop = True\n",
    "    FLAGS.sparse_to_dense = False\n",
    "    \n",
    "  if 'pair' in FLAGS.train_input:\n",
    "    FLAGS.batch_size = int(FLAGS.batch_size / 2)\n",
    "    if FLAGS.max_len:\n",
    "      FLAGS.max_len *= 2\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import gezi\n",
    "logging = gezi.logging\n",
    "\n",
    "eval_langs = ['es', 'it', 'tr']\n",
    "\n",
    "def evaluate(y_true, y_pred, x):\n",
    "  if FLAGS.task == 'toxic':\n",
    "    try:\n",
    "      y_true = y_true[:,0]\n",
    "      y_pred = y_pred[:,0]\n",
    "    except Exception:\n",
    "      pass\n",
    "    if y_pred.max() > 1. or y_pred.min() < 0:\n",
    "      y_pred = gezi.sigmoid(y_pred)\n",
    "    result = OrderedDict()\n",
    "    loss = log_loss(y_true, y_pred)\n",
    "    result['loss'] = loss\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    result['auc/all'] = auc\n",
    "      \n",
    "    if 'lang' in x:\n",
    "      x['y_true'] = y_true\n",
    "      x['pred'] = y_pred\n",
    "      x['lang'] = gezi.decode(x['lang'])\n",
    "\n",
    "      df = pd.DataFrame(x) \n",
    "      df = shuffle(df)\n",
    "      gezi.pprint(pd.concat([df[df.y_true==0].sample(5), df[df.y_true==1].sample(5)]), \n",
    "                  print_fn=logging.info, desc='preds:')\n",
    "\n",
    "      for lang in eval_langs:\n",
    "        df_ = df[df.lang==lang]\n",
    "        if len(df_):\n",
    "          auc = roc_auc_score(df_.y_true, df_.pred)\n",
    "          result[f'auc/{lang}'] = auc\n",
    "  elif FLAGS.task == 'lang':\n",
    "    results = np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1)\n",
    "    result = {'acc': np.sum(results) / len(results)}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def get_lang_id(x):\n",
    "  return tf.cast(tf.math.equal(x, 'en'), tf.int32) \\\n",
    "         + tf.cast(tf.math.equal(x, 'es'), tf.int32) * 2 \\\n",
    "         + tf.cast(tf.math.equal(x, 'it'), tf.int32) * 3 \\\n",
    "         + tf.cast(tf.math.equal(x, 'tr'), tf.int32) * 4 \\\n",
    "         + tf.cast(tf.math.equal(x, 'fr'), tf.int32) * 5 \\\n",
    "         + tf.cast(tf.math.equal(x, 'pt'), tf.int32) * 6 \\\n",
    "         + tf.cast(tf.math.equal(x, 'ru'), tf.int32) * 7 \\\n",
    "         - 1\n",
    "\n",
    "# srcs = ['unintended', 'toxic', 'test']\n",
    "def get_src_id(x):\n",
    "  return tf.cast(tf.math.equal(x, 'unintended'), tf.int32) \\\n",
    "         + tf.cast(tf.math.equal(x, 'toxic'), tf.int32) * 2 \\\n",
    "         + tf.cast(tf.math.equal(x, 'test'), tf.int32) * 3 \\\n",
    "         - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import melt\n",
    "\n",
    "class Dataset(melt.Dataset):\n",
    "  def __init__(self, subset='valid', **kwargs):\n",
    "    super(Dataset, self).__init__(subset, **kwargs)\n",
    "\n",
    "  def parse(self, example):\n",
    "    MAX_LEN = FLAGS.max_len\n",
    "    features_dict = {\n",
    "      'toxic': tf.io.FixedLenFeature([], tf.float32),\n",
    "      'id': tf.io.FixedLenFeature([], tf.string),\n",
    "      # 'comment_text': tf.io.FixedLenFeature([], tf.string), # TODO\n",
    "    }\n",
    "    features_dict['input_word_ids'] = tf.io.VarLenFeature(tf.int64) if not MAX_LEN else  tf.io.FixedLenFeature([MAX_LEN], tf.int64)\n",
    "\n",
    "    def _adds(names, dtype=None, length=None):\n",
    "      dtype_ = dtype\n",
    "      for name in names:\n",
    "        if name in self.example:\n",
    "          dtype = dtype_ or self.example[name].dtype \n",
    "          if length:\n",
    "            features_dict[name] = tf.io.FixedLenFeature([length], dtype)\n",
    "          else:\n",
    "            features_dict[name] = tf.io.FixedLenFeature([], dtype)\n",
    "\n",
    "    _adds(['lang', 'src'], tf.string)\n",
    "    _adds(['trans'], tf.int64, 1)\n",
    "\n",
    "    _adds(['input_mask', 'all_segment_id'], tf.int64, MAX_LEN)\n",
    "    \n",
    "    _adds(toxic_types)\n",
    "\n",
    "    features = self.parse_(serialized=example, features=features_dict)\n",
    "\n",
    "    features['lang_'] = tf.expand_dims(get_lang_id(features['lang']), -1)\n",
    "    features['src_'] = tf.expand_dims(get_src_id(features['src']), -1)\n",
    "\n",
    "    def _casts(names, dtype=tf.int32):\n",
    "      for name in names:\n",
    "        if name in features:\n",
    "          features[name] = tf.cast(features[name], dtype)\n",
    "\n",
    "    _casts(['input_word_ids', 'input_mask', 'all_segment_id', 'trans'])\n",
    "\n",
    "    x = features\n",
    "\n",
    "    if FLAGS.task == 'toxic':\n",
    "      y = features['toxic']\n",
    "    #     y = tf.cast(features['toxic'] > 0.5, tf.float32)\n",
    "      keys = ['toxic', *toxic_types]\n",
    "      for key in keys:\n",
    "        if key not in features:\n",
    "          features[key] = tf.zeros_like(features['toxic'])\n",
    "          \n",
    "      _casts(toxic_types, tf.float32)\n",
    "          \n",
    "      melt.append_dim(features, keys)\n",
    "\n",
    "      if FLAGS.multi_head:\n",
    "        y = tf.concat([features[key] for key in keys], 1)\n",
    "\n",
    "\n",
    "    elif FLAGS.task == 'lang':\n",
    "      y = tf.one_hot(features['lang_'], len(langs))\n",
    "\n",
    " \n",
    "    # self.padding_values = (melt.get_padding_values(features, 1), 1.)\n",
    "\n",
    "    return x, y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "import tensorflow as tf\n",
    "\n",
    "def calc_loss(y_true, y_pred):\n",
    "  pass\n",
    "\n",
    "def focal_loss(gamma=1.5, alpha=.2):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def get_loss_fn():\n",
    "#   return tf.compat.v1.losses.sigmoid_cross_entropy\n",
    "  return tf.keras.losses.BinaryCrossentropy()\n",
    "#   return focal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0425 00:04:51.617229 140030697813824 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0425 00:04:51.617975 140030697813824 file_utils.py:57] TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import transformers\n",
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS.use_mlp=1\n",
    "# FLAGS.use_lang=1\n",
    "# FLAGS.use_src=1\n",
    "# FLAGS.use_trans=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XlmModel(keras.Model):\n",
    "  def __init__(self):\n",
    "    super(XlmModel, self).__init__() \n",
    "\n",
    "    pretrained = FLAGS.pretrained\n",
    "\n",
    "    with gezi.Timer(f'load xlm_model from {pretrained}', True, logging.info):\n",
    "      self.transformer = TFAutoModel.from_pretrained(pretrained)\n",
    "\n",
    "    # if FLAGS.pretrained2:\n",
    "    #   logging.info(f'load lang_model from {FLAGS.pretrained2}')\n",
    "    #   self.transformer.load_weights(FLAGS.pretrained2)\n",
    "\n",
    "    if FLAGS.freeze_pretrained:\n",
    "      self.transformer.trainable = False\n",
    "    # dims = [32]\n",
    "    # self.mlp = melt.layers.MLP(dims)\n",
    "    if FLAGS.use_lang:\n",
    "      self.lang_emb = keras.layers.Embedding(len(langs), 32, name='lang_emb')\n",
    "    if FLAGS.use_src:\n",
    "      self.src_emb = keras.layers.Embedding(len(srcs), 32, name='src_emb')\n",
    "    if FLAGS.use_trans:\n",
    "      self.trans_emb = keras.layers.Embedding(2, 32, name='trans_emb')\n",
    "    \n",
    "    if FLAGS.use_mlp:\n",
    "      self.mlp = melt.layers.MLP([256,128])\n",
    "    odim = len(toxic_types) + 1 if FLAGS.multi_head else 1\n",
    "    self.dense = keras.layers.Dense(odim, activation='sigmoid')\n",
    "\n",
    "  def call(self, input):\n",
    "    input_word_ids = input['input_word_ids']\n",
    "    # tf.print(input_word_ids)\n",
    "    # tf.print(input['id'])\n",
    "    # tf.print(input['toxic'])\n",
    "    x = self.transformer(input_word_ids)[0]\n",
    "    x = x[:, 0, :]\n",
    "    \n",
    "    others = []\n",
    "    if FLAGS.use_lang:\n",
    "      lang_ids = input['lang_']\n",
    "      x_lang = tf.squeeze(self.lang_emb(lang_ids), 1)\n",
    "      others += [x_lang]\n",
    "  \n",
    "    if FLAGS.use_src:\n",
    "      srcs = input['src_']\n",
    "      x_src = tf.squeeze(self.src_emb(srcs), 1)\n",
    "      others += [x_src]\n",
    "        \n",
    "    if FLAGS.use_trans:\n",
    "      trans = input['trans']\n",
    "      x_trans = tf.squeeze(self.trans_emb(trans), 1)\n",
    "      others += [x_trans]\n",
    "    \n",
    "    if others:\n",
    "      x = tf.concat([x, *others], -1)\n",
    "      \n",
    "    if FLAGS.use_mlp:\n",
    "      x = self.mlp(x)\n",
    "    x = self.dense(x)\n",
    "    # tf.print(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def xlm_model():\n",
    "  inputs = {\n",
    "            'input_word_ids': Input(shape=(FLAGS.max_len,), dtype=tf.int32, name=\"input_word_ids\"),\n",
    "            'lang_': Input(shape=(1,), dtype=tf.int32, name=\"lang_\"),\n",
    "            'src_': Input(shape=(1,), dtype=tf.int32, name=\"src_\"),\n",
    "            'trans': Input(shape=(1,), dtype=tf.int32, name=\"trans\"),\n",
    "            }\n",
    "  out = XlmModel()(inputs)\n",
    "\n",
    "  model = keras.Model(inputs=list(inputs.values()), outputs=out)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = xlm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:04:51 0:00:00 fcntl.floc with lock_file /root/.melt.lock (If hang here means other programs calling melt.init have not finished yet)\n",
      "2020-04-25 00:04:52 0:00:00 Tf dataset and Tf model train in Eager mode, keras 1, distributed:False\n",
      "2020-04-25 00:04:52 0:00:00 log_level: 20 (try --debug to show more or --log_level=(> 20) to show less(no INFO), try --verbose to show train/valid loss intervaly)\n",
      "2020-04-25 00:04:52 0:00:00 batch_size: 256 eval_batch_size: 256 batch_size_per_gpu: 32 num_gpus: 8 gpu: [0, 1, 2, 3, 4, 5, 6, 7] CUDA_VISIABLE_DEVICES=[] work_mode: train distributed: False horovod: False\n",
      "2020-04-25 00:04:57 0:00:05 model: [unintended] model_dir: [../working/exps/unintended]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "import os\n",
    "import melt\n",
    "\n",
    "fit = melt.fit\n",
    "melt.init()\n",
    "loss_fn = get_loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:04:57 0:00:05 load xlm_model from ../input/tf-xlm-roberta-base/ start\n",
      "I0425 00:04:57.795662 140030697813824 configuration_utils.py:281] loading configuration file ../input/tf-xlm-roberta-base/config.json\n",
      "I0425 00:04:57.796745 140030697813824 configuration_utils.py:319] Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "I0425 00:04:57.797995 140030697813824 modeling_tf_utils.py:388] loading weights file ../input/tf-xlm-roberta-base/tf_model.h5\n",
      "2020-04-25 00:05:13 0:00:22 load xlm_model from ../input/tf-xlm-roberta-base/ duration: 16.10259199142456\n"
     ]
    }
   ],
   "source": [
    "strategy = melt.distributed.get_strategy()\n",
    "with strategy.scope():\n",
    "  model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model=model):\n",
    "  fit(model,  \n",
    "      loss_fn,\n",
    "      Dataset,\n",
    "      eval_fn=evaluate,\n",
    "      eval_keys=['lang'],\n",
    "      )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:05:19 0:00:28 -------Round: 0 mode: None train_input:[jigsaw-unintended-bias-train] valid_input:[validation] train_dirs:[1] valid_dir: ../input/tfrecords/xlm/validation\n",
      "2020-04-25 00:05:19 0:00:28 --start_hour=jigsaw-unintended-bias-train --end_hour=validation root: ../input/tfrecords/xlm\n",
      "2020-04-25 00:05:23 0:00:31 Model: \"tf_roberta_model\"\n",
      "2020-04-25 00:05:23 0:00:31 _________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 Layer (type)                 Output Shape              Param #   \n",
      "2020-04-25 00:05:23 0:00:31 =================================================================\n",
      "2020-04-25 00:05:23 0:00:31 roberta (TFRobertaMainLayer) ((None, 192, 768), (None, 278043648 \n",
      "2020-04-25 00:05:23 0:00:31 =================================================================\n",
      "2020-04-25 00:05:23 0:00:31 Total params: 278,043,648\n",
      "2020-04-25 00:05:23 0:00:31 Trainable params: 278,043,648\n",
      "2020-04-25 00:05:23 0:00:31 Non-trainable params: 0\n",
      "2020-04-25 00:05:23 0:00:31 _________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 Model: \"xlm_model\"\n",
      "2020-04-25 00:05:23 0:00:31 _________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 Layer (type)                 Output Shape              Param #   \n",
      "2020-04-25 00:05:23 0:00:31 =================================================================\n",
      "2020-04-25 00:05:23 0:00:31 tf_roberta_model (TFRobertaM ((None, 192, 768), (None, 278043648 \n",
      "2020-04-25 00:05:23 0:00:31 _________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 dense (Dense)                multiple                  769       \n",
      "2020-04-25 00:05:23 0:00:31 =================================================================\n",
      "2020-04-25 00:05:23 0:00:31 Total params: 278,044,417\n",
      "2020-04-25 00:05:23 0:00:31 Trainable params: 278,044,417\n",
      "2020-04-25 00:05:23 0:00:31 Non-trainable params: 0\n",
      "2020-04-25 00:05:23 0:00:31 _________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 Model: \"model\"\n",
      "2020-04-25 00:05:23 0:00:31 __________________________________________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2020-04-25 00:05:23 0:00:31 ==================================================================================================\n",
      "2020-04-25 00:05:23 0:00:31 input_word_ids (InputLayer)     [(None, 192)]        0                                            \n",
      "2020-04-25 00:05:23 0:00:31 __________________________________________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 lang_ (InputLayer)              [(None, 1)]          0                                            \n",
      "2020-04-25 00:05:23 0:00:31 __________________________________________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 src_ (InputLayer)               [(None, 1)]          0                                            \n",
      "2020-04-25 00:05:23 0:00:31 __________________________________________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 trans (InputLayer)              [(None, 1)]          0                                            \n",
      "2020-04-25 00:05:23 0:00:31 __________________________________________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 xlm_model (XlmModel)            (None, 1)            278044417   input_word_ids[0][0]             \n",
      "2020-04-25 00:05:23 0:00:31                                                                  lang_[0][0]                      \n",
      "2020-04-25 00:05:23 0:00:31                                                                  src_[0][0]                       \n",
      "2020-04-25 00:05:23 0:00:31                                                                  trans[0][0]                      \n",
      "2020-04-25 00:05:23 0:00:31 ==================================================================================================\n",
      "2020-04-25 00:05:23 0:00:31 Total params: 278,044,417\n",
      "2020-04-25 00:05:23 0:00:31 Trainable params: 278,044,417\n",
      "2020-04-25 00:05:23 0:00:31 Non-trainable params: 0\n",
      "2020-04-25 00:05:23 0:00:31 __________________________________________________________________________________________________\n",
      "2020-04-25 00:05:23 0:00:31 num_train_examples: 1902194 num_steps_per_epoch: 7431\n",
      "2020-04-25 00:05:23 0:00:31 num_valid_examples: 8000  \n",
      "2020-04-25 00:05:23 0:00:32 num_test_examples: 63812   \n",
      "2020-04-25 00:05:23 0:00:32 round: 0 optimizer: <husky.optimization.AdamWeightDecay object at 0x7f58d46202e8> lr: <husky.optimization.WarmUp object at 0x7f58d46207b8> init_lr: 3e-05\n",
      "2020-04-25 00:05:23 0:00:32 total_steps: 7431 num_warmup_steps: 743 end_lr: 0.0\n",
      "2020-04-25 00:05:23 0:00:32 latest ckpt to restore: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 7431 steps\n",
      "   1/7431 [..............................] - ETA: 462:46:59 - loss: 0.9352 - acc: 0.0039 - auc: 0.4650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:09:10 0:04:19 Model total training parameters is: 278044417 with initial l2: 0.01613772557785255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 742/7431 [=>............................] - ETA: 2:40:56 - loss: 0.3334 - acc: 0.6628 - auc: 0.6782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 473.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.7 insts/s: 176.9 1epoch: 2.99h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:23:58 0:19:06 preds:\n",
      " +------+--------+----------+-----------+\n",
      "|   id | lang   |   y_true |      pred |\n",
      "|------+--------+----------+-----------|\n",
      "| 3199 | tr     |        0 | 0.133228  |\n",
      "| 4809 | tr     |        0 | 0.0157403 |\n",
      "| 6767 | tr     |        0 | 0.0218162 |\n",
      "| 6353 | tr     |        0 | 0.0178048 |\n",
      "|  753 | tr     |        0 | 0.105038  |\n",
      "| 3323 | es     |        1 | 0.333838  |\n",
      "| 1298 | es     |        1 | 0.369389  |\n",
      "| 1701 | es     |        1 | 0.062876  |\n",
      "| 6254 | es     |        1 | 0.683949  |\n",
      "| 2193 | tr     |        1 | 0.1125    |\n",
      "+------+--------+----------+-----------+\n",
      "2020-04-25 00:23:58 0:19:06 eval_step: 1 step: 743 epoch: 0.1\n",
      "2020-04-25 00:23:58 0:19:06 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.324576 |  0.878994 | 0.861797 | 0.820312 | 0.951364 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/7431 [====>.........................] - ETA: 2:10:56 - loss: 0.2872 - acc: 0.7006 - auc: 0.8423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 560.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 213.5 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 41s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:38:51 0:33:59 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 1839 | it     |        0 | 0.00513735 |\n",
      "| 5971 | tr     |        0 | 0.00856704 |\n",
      "| 3238 | tr     |        0 | 0.00382256 |\n",
      "| 2622 | es     |        0 | 0.101831   |\n",
      "| 6823 | tr     |        0 | 0.0212523  |\n",
      "| 7765 | es     |        1 | 0.0586432  |\n",
      "| 1912 | tr     |        1 | 0.129716   |\n",
      "| 3480 | es     |        1 | 0.105323   |\n",
      "| 7568 | tr     |        1 | 0.0640199  |\n",
      "| 1322 | tr     |        1 | 0.135325   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 00:38:51 0:33:59 eval_step: 2 step: 1486 epoch: 0.2\n",
      "2020-04-25 00:38:51 0:33:59 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.346431 |  0.889118 | 0.864199 | 0.826024 | 0.966873 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2228/7431 [=======>......................] - ETA: 1:51:09 - loss: 0.2698 - acc: 0.7023 - auc: 0.8547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 467.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 212.9 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 00:53:42 0:48:51 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 2090 | es     |        0 | 0.0886887  |\n",
      "| 1154 | es     |        0 | 0.00520227 |\n",
      "| 3864 | es     |        0 | 0.00716849 |\n",
      "| 6696 | tr     |        0 | 0.0448156  |\n",
      "| 1593 | tr     |        0 | 0.0175775  |\n",
      "| 6288 | it     |        1 | 0.630648   |\n",
      "| 2505 | es     |        1 | 0.435012   |\n",
      "| 7932 | tr     |        1 | 0.280901   |\n",
      "| 1157 | tr     |        1 | 0.39242    |\n",
      "| 1825 | es     |        1 | 0.396876   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 00:53:43 0:48:51 eval_step: 3 step: 2229 epoch: 0.3\n",
      "2020-04-25 00:53:43 0:48:51 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.313814 |  0.893591 | 0.871533 | 0.830916 |  0.96759 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2971/7431 [==========>...................] - ETA: 1:33:44 - loss: 0.2609 - acc: 0.7001 - auc: 0.8579"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 466.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 213.4 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 01:08:33 1:03:42 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 5848 | es     |        0 | 0.00651061 |\n",
      "| 7934 | tr     |        0 | 0.0059156  |\n",
      "| 5591 | tr     |        0 | 0.0777779  |\n",
      "| 3281 | it     |        0 | 0.217845   |\n",
      "|  126 | tr     |        0 | 0.00536487 |\n",
      "| 6687 | es     |        1 | 0.639021   |\n",
      "| 7674 | it     |        1 | 0.570761   |\n",
      "| 1833 | it     |        1 | 0.25348    |\n",
      "|  639 | es     |        1 | 0.350199   |\n",
      "| 1897 | es     |        1 | 0.0624705  |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 01:08:33 1:03:42 eval_step: 4 step: 2972 epoch: 0.4\n",
      "2020-04-25 01:08:33 1:03:42 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.339999 |  0.889159 | 0.863167 | 0.822137 |  0.96963 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3714/7431 [=============>................] - ETA: 1:17:21 - loss: 0.2550 - acc: 0.7014 - auc: 0.8610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 370.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 213.5 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 41s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 01:23:27 1:18:36 preds:\n",
      " +------+--------+----------+-----------+\n",
      "|   id | lang   |   y_true |      pred |\n",
      "|------+--------+----------+-----------|\n",
      "| 3497 | es     |        0 | 0.382413  |\n",
      "| 3354 | tr     |        0 | 0.0250918 |\n",
      "| 7961 | tr     |        0 | 0.03199   |\n",
      "| 7664 | it     |        0 | 0.0143195 |\n",
      "| 6215 | it     |        0 | 0.774306  |\n",
      "| 3682 | tr     |        1 | 0.232097  |\n",
      "| 6811 | es     |        1 | 0.185372  |\n",
      "| 6713 | es     |        1 | 0.0899882 |\n",
      "| 6144 | es     |        1 | 0.228026  |\n",
      "| 4441 | tr     |        1 | 0.0202194 |\n",
      "+------+--------+----------+-----------+\n",
      "2020-04-25 01:23:27 1:18:36 eval_step: 5 step: 3715 epoch: 0.5\n",
      "2020-04-25 01:23:27 1:18:36 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.320495 |  0.890745 | 0.863924 | 0.825928 | 0.972123 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457/7431 [================>.............] - ETA: 1:01:31 - loss: 0.2506 - acc: 0.7032 - auc: 0.8661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 449.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 212.6 1epoch: 2.49h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 40s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 01:38:20 1:33:29 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "|  429 | tr     |        0 | 0.0104487  |\n",
      "| 2971 | tr     |        0 | 0.00658506 |\n",
      "| 4408 | es     |        0 | 0.00374429 |\n",
      "| 3407 | es     |        0 | 0.00816565 |\n",
      "| 1613 | tr     |        0 | 0.00627309 |\n",
      "| 6777 | tr     |        1 | 0.056119   |\n",
      "| 1160 | it     |        1 | 0.236453   |\n",
      "| 7854 | tr     |        1 | 0.0656292  |\n",
      "| 6570 | tr     |        1 | 0.313512   |\n",
      "| 3323 | es     |        1 | 0.289881   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 01:38:20 1:33:29 eval_step: 6 step: 4458 epoch: 0.6\n",
      "2020-04-25 01:38:20 1:33:29 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.327569 |  0.896039 | 0.875232 | 0.830034 | 0.972449 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200/7431 [===================>..........] - ETA: 45:56 - loss: 0.2478 - acc: 0.7003 - auc: 0.8648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 473.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 212.9 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 01:53:13 1:48:21 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 6905 | it     |        0 | 0.0799596  |\n",
      "| 3943 | it     |        0 | 0.0344114  |\n",
      "| 3170 | it     |        0 | 0.00815768 |\n",
      "|  325 | es     |        0 | 0.00653376 |\n",
      "| 2109 | it     |        0 | 0.00502361 |\n",
      "| 5716 | it     |        1 | 0.0707006  |\n",
      "| 5675 | es     |        1 | 0.485462   |\n",
      "| 5374 | it     |        1 | 0.0346515  |\n",
      "| 6183 | it     |        1 | 0.0527609  |\n",
      "| 3015 | es     |        1 | 0.377167   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 01:53:13 1:48:21 eval_step: 7 step: 5201 epoch: 0.7\n",
      "2020-04-25 01:53:13 1:48:21 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.321729 |  0.895473 | 0.875151 | 0.828445 | 0.973476 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5943/7431 [======================>.......] - ETA: 30:32 - loss: 0.2456 - acc: 0.6987 - auc: 0.8688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 356.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 213.2 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 42s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 02:08:08 2:03:16 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 4563 | es     |        0 | 0.00465111 |\n",
      "| 7784 | tr     |        0 | 0.0174455  |\n",
      "| 4361 | tr     |        0 | 0.00684921 |\n",
      "|  371 | tr     |        0 | 0.00534528 |\n",
      "| 4977 | it     |        0 | 0.00488724 |\n",
      "| 3874 | it     |        1 | 0.478022   |\n",
      "| 4412 | tr     |        1 | 0.0837321  |\n",
      "| 5372 | tr     |        1 | 0.0235854  |\n",
      "| 2997 | tr     |        1 | 0.151698   |\n",
      "| 4645 | es     |        1 | 0.114412   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 02:08:08 2:03:16 eval_step: 8 step: 5944 epoch: 0.8\n",
      "2020-04-25 02:08:08 2:03:16 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.323199 |  0.892722 | 0.868214 | 0.826518 |  0.97524 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6686/7431 [=========================>....] - ETA: 15:15 - loss: 0.2438 - acc: 0.7010 - auc: 0.8696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 449.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 212.5 1epoch: 2.49h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 02:23:00 2:18:09 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 7656 | it     |        0 | 0.00884086 |\n",
      "| 7857 | tr     |        0 | 0.0134664  |\n",
      "|  108 | es     |        0 | 0.00896453 |\n",
      "| 1015 | es     |        0 | 0.273741   |\n",
      "| 6726 | tr     |        0 | 0.030106   |\n",
      "| 2817 | it     |        1 | 0.0832875  |\n",
      "| 1619 | tr     |        1 | 0.0488885  |\n",
      "|  767 | it     |        1 | 0.0363719  |\n",
      "| 6348 | es     |        1 | 0.310347   |\n",
      "| 1553 | es     |        1 | 0.563177   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 02:23:00 2:18:09 eval_step: 9 step: 6687 epoch: 0.9\n",
      "2020-04-25 02:23:00 2:18:09 valid_metrics:\n",
      " +----------+-----------+----------+----------+----------+---------+\n",
      "|     loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|----------+-----------+----------+----------+----------+---------|\n",
      "| 0.322391 |  0.893533 | 0.870866 | 0.826253 | 0.974562 |    8000 |\n",
      "+----------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7429/7431 [============================>.] - ETA: 2s - loss: 0.2421 - acc: 0.7014 - auc: 0.8684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|##########| 32/32 [00:00<00:00, 567.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " steps/s: 0.8 insts/s: 213.2 1epoch: 2.48h "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-25 02:37:52 2:33:00 preds:\n",
      " +------+--------+----------+------------+\n",
      "|   id | lang   |   y_true |       pred |\n",
      "|------+--------+----------+------------|\n",
      "| 2265 | tr     |        0 | 0.0240203  |\n",
      "| 4993 | tr     |        0 | 0.00633908 |\n",
      "| 1826 | it     |        0 | 0.0199839  |\n",
      "| 2883 | es     |        0 | 0.00933557 |\n",
      "| 5608 | tr     |        0 | 0.0058497  |\n",
      "| 1921 | tr     |        1 | 0.0529662  |\n",
      "| 2442 | it     |        1 | 0.108366   |\n",
      "| 6235 | it     |        1 | 0.259334   |\n",
      "| 1590 | es     |        1 | 0.294917   |\n",
      "| 6659 | it     |        1 | 0.114269   |\n",
      "+------+--------+----------+------------+\n",
      "2020-04-25 02:37:52 2:33:00 eval_step: 10 step: 7430 epoch: 1.0\n",
      "2020-04-25 02:37:52 2:33:00 valid_metrics:\n",
      " +---------+-----------+----------+----------+----------+---------+\n",
      "|    loss |   auc/all |   auc/es |   auc/it |   auc/tr |   insts |\n",
      "|---------+-----------+----------+----------+----------+---------|\n",
      "| 0.32273 |  0.894193 | 0.871997 | 0.827132 | 0.974209 |    8000 |\n",
      "+---------+-----------+----------+----------+----------+---------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7431/7431 [==============================] - 9147s 1s/step - loss: 0.2421 - acc: 0.6842 - auc: 0.8891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|##########| 250/250 [00:00<00:00, 576.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 97s 387ms/step\n"
     ]
    }
   ],
   "source": [
    "# FLAGS.train_input=','.join([f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-unintended-bias-train',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train-google-tr-cleaned',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train-google-it-cleaned',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train-google-es-cleaned',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train-google-ru-cleaned',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train-google-pt-cleaned',\n",
    "#                            f'{RECORDS_PATH}/{mark}/jigsaw-toxic-comment-train-google-fr-cleaned'])\n",
    "FLAGS.train_input = f'{RECORDS_PATH}/{mark}/jigsaw-unintended-bias-train'\n",
    "FLAGS.learning_rate=3e-5\n",
    "FLAGS.opt_epsilon=1e-8\n",
    "FLAGS.num_epochs=1\n",
    "FLAGS.vie=0.1\n",
    "FLAGS.do_test=1\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odir = '../working/exps/toxic-mix-lang'\n",
    "# os.system(f'mkdir -p f{odir}')\n",
    "# model.save_weights(f'{odir}/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.078021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.005713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic\n",
       "0   0  0.020160\n",
       "1   1  0.004429\n",
       "2   2  0.078021\n",
       "3   3  0.005641\n",
       "4   4  0.005713"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{FLAGS.model_dir}/infos/test_1.csv')\n",
    "df.to_csv('./submission.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import traceback\n",
    "# try:\n",
    "#   optimizer = gezi.get('optimizer')\n",
    "#   ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "#   manager = tf.train.CheckpointManager(ckpt, FLAGS.model_dir, max_to_keep=1, checkpoint_name='model.ckpt')\n",
    "#   manager.save()\n",
    "#   model.save_weights(f'{FLAGS.model_dir}/model_weight.h5')\n",
    "# except Exception:\n",
    "#   print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0425 02:39:43.036449 140030697813824 configuration_utils.py:142] Configuration saved in ../working/exps/unintended/tf-xlm-roberta-base/config.json\n",
      "I0425 02:39:45.432259 140030697813824 modeling_tf_utils.py:246] Model weights saved in ../working/exps/unintended/tf-xlm-roberta-base/tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "os.system(f'mkdir -p {FLAGS.model_dir}/tf-xlm-roberta-base')\n",
    "model.layers[-1].layers[0].save_pretrained(f'{FLAGS.model_dir}/tf-xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
