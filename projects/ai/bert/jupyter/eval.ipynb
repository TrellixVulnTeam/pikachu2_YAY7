{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import melt\n",
    "melt.init_flags()\n",
    "FLAGS = melt.get_flags()\n",
    "FLAGS.pretrained = '../input/tf-xlm-roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 13:29:03.503679 140585931941696 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0426 13:29:03.504853 140585931941696 file_utils.py:57] TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from model import xlm_model as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 13:29:15.424333 140585931941696 logging.py:97] load xlm_model from ../input/tf-xlm-roberta-large start\n",
      "I0426 13:29:15.425956 140585931941696 configuration_utils.py:281] loading configuration file ../input/tf-xlm-roberta-large/config.json\n",
      "I0426 13:29:15.426978 140585931941696 configuration_utils.py:319] Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "I0426 13:29:15.428368 140585931941696 modeling_tf_utils.py:388] loading weights file ../input/tf-xlm-roberta-large/tf_model.h5\n",
      "I0426 13:29:26.210473 140585931941696 logging.py:97] load xlm_model from ../input/tf-xlm-roberta-large duration: 10.7861328125\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) ((None, None, 1024), (Non 559890432 \n",
      "=================================================================\n",
      "Total params: 559,890,432\n",
      "Trainable params: 559,890,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"xlm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tf_roberta_model (TFRobertaM ((None, None, 1024), (Non 559890432 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1025      \n",
      "=================================================================\n",
      "Total params: 559,891,457\n",
      "Trainable params: 559,891,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "xlm_model (XlmModel)         (None, 1)                 559891457 \n",
      "=================================================================\n",
      "Total params: 559,891,457\n",
      "Trainable params: 559,891,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "melt.print_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "xlm_model (XlmModel)         (None, 1)                 559891457 \n",
      "=================================================================\n",
      "Total params: 559,891,457\n",
      "Trainable params: 559,891,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xlm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tf_roberta_model (TFRobertaM ((None, None, 1024), (Non 559890432 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1025      \n",
      "=================================================================\n",
      "Total params: 559,891,457\n",
      "Trainable params: 559,891,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 13:38:04.556453 140585931941696 configuration_utils.py:281] loading configuration file ../input/tf-xlm-roberta-large/config.json\n",
      "I0426 13:38:04.557458 140585931941696 configuration_utils.py:319] Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "I0426 13:38:04.558401 140585931941696 modeling_tf_utils.py:388] loading weights file ../input/tf-xlm-roberta-large/tf_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load xlm_model from ../input/tf-xlm-roberta-large start\n",
      "load xlm_model from ../input/tf-xlm-roberta-large duration: 4.168493270874023\n"
     ]
    }
   ],
   "source": [
    "import gezi\n",
    "from transformers import TFAutoModel\n",
    "def xlm_model():\n",
    "  pretrained = FLAGS.pretrained \n",
    "  with gezi.Timer(f'load xlm_model from {pretrained}', True, print):\n",
    "    transformer = TFAutoModel.from_pretrained(pretrained)\n",
    "  input_word_ids = tf.keras.Input(shape=(FLAGS.max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "  sequence_output = transformer(input_word_ids)[0]\n",
    "  cls_token = sequence_output[:, 0, :]\n",
    "  odim = len(toxic_types) + 1 if FLAGS.multi_head else 1\n",
    "  out = tf.keras.layers.Dense(odim, activation='sigmoid')(cls_token)\n",
    "\n",
    "  model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n",
    "\n",
    "  return model\n",
    "model = xlm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fd9683dfe80>,\n",
       " <transformers.modeling_tf_roberta.TFRobertaModel at 0x7fd9683dff28>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x7fd9487dc978>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fd948740e48>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='../working/exps/v2/toxic-multi-en-finetune-unint-large'\n",
    "model.load_weights(f'{root}/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'mkdir -p {root}/tf-xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 13:42:54.188905 140585931941696 configuration_utils.py:142] Configuration saved in ../working/exps/v2/toxic-multi-en-finetune-unint-large/tf-xlm-roberta-large/config.json\n",
      "I0426 13:42:58.403539 140585931941696 modeling_tf_utils.py:246] Model weights saved in ../working/exps/v2/toxic-multi-en-finetune-unint-large/tf-xlm-roberta-large/tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.layers[1].save_pretrained(f'{root}/tf-xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'save_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b0d21e29eb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f{root}/dense.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'save_weights'"
     ]
    }
   ],
   "source": [
    "model.layers[3].save_weights('f{root}/dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.modeling_tf_roberta.TFRobertaMainLayer at 0x7fd9683db240>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 12:15:21.764256 140167830091584 configuration_utils.py:142] Configuration saved in ../working/exps/xlm/toxic-from-mix/tf-xlm-roberta-base/config.json\n",
      "I0426 12:15:23.937429 140167830091584 modeling_tf_utils.py:246] Model weights saved in ../working/exps/xlm/toxic-from-mix/tf-xlm-roberta-base/tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "os.system(f'mkdir -p {root}')\n",
    "model.layers[-1].layers[0].save_pretrained(f'{root}/tf-xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].save_weights('../working/exps/v2/toxic-multi-en-finetune-unint/lang_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 12:15:28.436675 140167830091584 logging.py:97] load xlm_model from ../input/tf-xlm-roberta-large start\n",
      "I0426 12:15:28.438077 140167830091584 configuration_utils.py:281] loading configuration file ../input/tf-xlm-roberta-large/config.json\n",
      "I0426 12:15:28.439062 140167830091584 configuration_utils.py:319] Model config XLMRobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "I0426 12:15:28.440359 140167830091584 modeling_tf_utils.py:388] loading weights file ../input/tf-xlm-roberta-large/tf_model.h5\n",
      "I0426 12:15:32.700306 140167830091584 logging.py:97] load xlm_model from ../input/tf-xlm-roberta-large duration: 4.2636330127716064\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 2 layers into a model with 1 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7050da1d1c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/tf-xlm-roberta-large'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../working/exps/v2/toxic-multi-en-finetune-unint-large/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    272\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    273\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   def compile(self,\n",
      "\u001b[0;32m/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   1258\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/env/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    683\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 2 layers into a model with 1 layers."
     ]
    }
   ],
   "source": [
    "FLAGS.pretrained = '../input/tf-xlm-roberta-large'\n",
    "model = Model()\n",
    "model.load_weights('../working/exps/v2/toxic-multi-en-finetune-unint-large/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].save_weights('../working/exps/v2/toxic-multi-en-finetune-unint-large/lang_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../working/exps/v1/debug/model_weight.h5')\n",
    "model.weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'identity_hate': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'input_word_ids': <tf.Tensor: shape=(32, 192), dtype=int32, numpy=\n",
       "  array([[     0,    152,   8331, ...,      1,      1,      1],\n",
       "         [     0,   2091,    221, ...,    177,     16,      2],\n",
       "         [     0, 203145,    126, ...,      1,      1,      1],\n",
       "         ...,\n",
       "         [     0,  13030,  20468, ...,      1,      1,      1],\n",
       "         [     0,    313,   1615, ...,      1,      1,      1],\n",
       "         [     0,  57157,    153, ...,      1,      1,      1]], dtype=int32)>,\n",
       "  'insult': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'obscene': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'severe_toxic': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'threat': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'toxic': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[1.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[1.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'id': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "  array([b'3605', b'3746', b'7269', b'2088', b'948', b'3396', b'1720',\n",
       "         b'6251', b'386', b'506', b'4667', b'6062', b'580', b'7969', b'303',\n",
       "         b'368', b'6129', b'7930', b'5096', b'4959', b'5852', b'4895',\n",
       "         b'7167', b'2903', b'785', b'3212', b'1667', b'682', b'4440',\n",
       "         b'1337', b'6142', b'4457'], dtype=object)>,\n",
       "  'lang': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "  array([b'tr', b'it', b'tr', b'it', b'es', b'es', b'es', b'es', b'es',\n",
       "         b'tr', b'it', b'it', b'tr', b'es', b'it', b'tr', b'tr', b'tr',\n",
       "         b'it', b'it', b'tr', b'tr', b'tr', b'es', b'es', b'tr', b'tr',\n",
       "         b'it', b'it', b'tr', b'it', b'it'], dtype=object)>,\n",
       "  'src': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "  array([b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test'], dtype=object)>,\n",
       "  'trans': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       "  array([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]], dtype=int32)>,\n",
       "  'lang_': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       "  array([[3],\n",
       "         [2],\n",
       "         [3],\n",
       "         [2],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2]], dtype=int32)>,\n",
       "  'src_': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       "  array([[2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2]], dtype=int32)>},\n",
       " <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gezi\n",
    "from dataset import Dataset\n",
    "ds = Dataset('valid').make_batch(32, gezi.list_files('../input/tfrecords/xlm/validation'))\n",
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'identity_hate': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'input_word_ids': <tf.Tensor: shape=(32, 192), dtype=int32, numpy=\n",
       "  array([[     0,    152,   8331, ...,      1,      1,      1],\n",
       "         [     0,   2091,    221, ...,    177,     16,      2],\n",
       "         [     0, 203145,    126, ...,      1,      1,      1],\n",
       "         ...,\n",
       "         [     0,  13030,  20468, ...,      1,      1,      1],\n",
       "         [     0,    313,   1615, ...,      1,      1,      1],\n",
       "         [     0,  57157,    153, ...,      1,      1,      1]], dtype=int32)>,\n",
       "  'insult': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'obscene': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'severe_toxic': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'threat': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'toxic': <tf.Tensor: shape=(32, 1, 1), dtype=float32, numpy=\n",
       "  array([[[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[1.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[1.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]],\n",
       "  \n",
       "         [[0.]]], dtype=float32)>,\n",
       "  'id': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "  array([b'3605', b'3746', b'7269', b'2088', b'948', b'3396', b'1720',\n",
       "         b'6251', b'386', b'506', b'4667', b'6062', b'580', b'7969', b'303',\n",
       "         b'368', b'6129', b'7930', b'5096', b'4959', b'5852', b'4895',\n",
       "         b'7167', b'2903', b'785', b'3212', b'1667', b'682', b'4440',\n",
       "         b'1337', b'6142', b'4457'], dtype=object)>,\n",
       "  'lang': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "  array([b'tr', b'it', b'tr', b'it', b'es', b'es', b'es', b'es', b'es',\n",
       "         b'tr', b'it', b'it', b'tr', b'es', b'it', b'tr', b'tr', b'tr',\n",
       "         b'it', b'it', b'tr', b'tr', b'tr', b'es', b'es', b'tr', b'tr',\n",
       "         b'it', b'it', b'tr', b'it', b'it'], dtype=object)>,\n",
       "  'src': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "  array([b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test', b'test', b'test', b'test',\n",
       "         b'test', b'test', b'test', b'test'], dtype=object)>,\n",
       "  'trans': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       "  array([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]], dtype=int32)>,\n",
       "  'lang_': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       "  array([[3],\n",
       "         [2],\n",
       "         [3],\n",
       "         [2],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2]], dtype=int32)>,\n",
       "  'src_': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       "  array([[2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2]], dtype=int32)>},\n",
       " <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate\n",
    "from husky.callbacks import EvalCallback\n",
    "eval_callback = EvalCallback(model, ds, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint('../working/exps/v1/debug'))\n",
    "model.weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
