{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.dirname(os.path.realpath(__file__))\n",
    "sys.path.append(os.path.join(dir, '../src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyt.model.WideDeep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', Parameter containing:\n",
       "  tensor([[-0.3139, -0.1626,  1.3040,  ...,  1.7971,  0.4902,  0.9819],\n",
       "          [-0.7473, -0.7696, -1.1402,  ..., -0.5170, -1.7026,  0.1562],\n",
       "          [ 0.0412,  0.5696,  0.9225,  ...,  0.5072,  0.5320, -1.7273],\n",
       "          ...,\n",
       "          [ 0.0753,  0.9876, -1.1700,  ...,  0.7941, -1.3211,  0.7633],\n",
       "          [-1.6442, -0.5121, -0.4860,  ..., -0.2770, -0.8105, -0.3317],\n",
       "          [-0.5837, -1.1456,  0.3455,  ..., -1.0004, -0.5467,  1.4226]],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.deep.emb.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3139, -0.1626,  1.3040,  ...,  1.7971,  0.4902,  0.9819],\n",
       "         [-0.7473, -0.7696, -1.1402,  ..., -0.5170, -1.7026,  0.1562],\n",
       "         [ 0.0412,  0.5696,  0.9225,  ...,  0.5072,  0.5320, -1.7273],\n",
       "         ...,\n",
       "         [ 0.0753,  0.9876, -1.1700,  ...,  0.7941, -1.3211,  0.7633],\n",
       "         [-1.6442, -0.5121, -0.4860,  ..., -0.2770, -0.8105, -0.3317],\n",
       "         [-0.5837, -1.1456,  0.3455,  ..., -1.0004, -0.5467,  1.4226]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.deep.emb.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140607087076872]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(id, m.deep.emb.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the identity of an object.\n",
       "\n",
       "This is guaranteed to be unique among simultaneously existing objects.\n",
       "(CPython uses the object's memory address.)\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wide.bias', Parameter containing:\n",
       "  tensor([0.], requires_grad=True)), ('wide.emb.weight', Parameter containing:\n",
       "  tensor([[-0.3607],\n",
       "          [ 0.4249],\n",
       "          [-0.3461],\n",
       "          ...,\n",
       "          [-0.0356],\n",
       "          [-1.2724],\n",
       "          [-0.4069]], requires_grad=True)), ('deep.emb.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3139, -0.1626,  1.3040,  ...,  1.7971,  0.4902,  0.9819],\n",
       "          [-0.7473, -0.7696, -1.1402,  ..., -0.5170, -1.7026,  0.1562],\n",
       "          [ 0.0412,  0.5696,  0.9225,  ...,  0.5072,  0.5320, -1.7273],\n",
       "          ...,\n",
       "          [ 0.0753,  0.9876, -1.1700,  ...,  0.7941, -1.3211,  0.7633],\n",
       "          [-1.6442, -0.5121, -0.4860,  ..., -0.2770, -0.8105, -0.3317],\n",
       "          [-0.5837, -1.1456,  0.3455,  ..., -1.0004, -0.5467,  1.4226]],\n",
       "         requires_grad=True)), ('deep.dense.weight', Parameter containing:\n",
       "  tensor([[ 0.0572, -0.0092,  0.0819, -0.1007, -0.1322,  0.0260,  0.0526, -0.1325,\n",
       "           -0.0264, -0.1290, -0.0183,  0.0625,  0.0486,  0.0752, -0.0136, -0.0544,\n",
       "            0.0980, -0.0402, -0.0898,  0.0923,  0.0132,  0.0091,  0.0901,  0.0429,\n",
       "            0.1383, -0.0308, -0.0349,  0.0184, -0.0535,  0.1138,  0.0696, -0.0778,\n",
       "            0.0977, -0.1372, -0.0701,  0.1160,  0.1242, -0.0041, -0.1010, -0.0510,\n",
       "           -0.0723, -0.0997,  0.0856, -0.1156, -0.0255, -0.0086,  0.0771,  0.1042,\n",
       "           -0.1112, -0.0047]], requires_grad=True)), ('deep.dense.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.1124], requires_grad=True)), ('dense.weight', Parameter containing:\n",
       "  tensor([[ 0.5110, -0.3250]], requires_grad=True)), ('dense.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.3893], requires_grad=True))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.nn.Embedding(3,6, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.6608, -0.6395,  0.2204, -0.3142, -1.6210,  0.0326],\n",
       "        [-1.3794,  1.5973,  0.3127, -0.9398, -0.5943, -0.9359]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('wide.bias', tensor([0.])),\n",
       "             ('wide.emb.weight', tensor([[-0.3607],\n",
       "                      [ 0.4249],\n",
       "                      [-0.3461],\n",
       "                      ...,\n",
       "                      [-0.0356],\n",
       "                      [-1.2724],\n",
       "                      [-0.4069]])),\n",
       "             ('deep.emb.weight',\n",
       "              tensor([[-0.3139, -0.1626,  1.3040,  ...,  1.7971,  0.4902,  0.9819],\n",
       "                      [-0.7473, -0.7696, -1.1402,  ..., -0.5170, -1.7026,  0.1562],\n",
       "                      [ 0.0412,  0.5696,  0.9225,  ...,  0.5072,  0.5320, -1.7273],\n",
       "                      ...,\n",
       "                      [ 0.0753,  0.9876, -1.1700,  ...,  0.7941, -1.3211,  0.7633],\n",
       "                      [-1.6442, -0.5121, -0.4860,  ..., -0.2770, -0.8105, -0.3317],\n",
       "                      [-0.5837, -1.1456,  0.3455,  ..., -1.0004, -0.5467,  1.4226]])),\n",
       "             ('deep.dense.weight',\n",
       "              tensor([[ 0.0572, -0.0092,  0.0819, -0.1007, -0.1322,  0.0260,  0.0526, -0.1325,\n",
       "                       -0.0264, -0.1290, -0.0183,  0.0625,  0.0486,  0.0752, -0.0136, -0.0544,\n",
       "                        0.0980, -0.0402, -0.0898,  0.0923,  0.0132,  0.0091,  0.0901,  0.0429,\n",
       "                        0.1383, -0.0308, -0.0349,  0.0184, -0.0535,  0.1138,  0.0696, -0.0778,\n",
       "                        0.0977, -0.1372, -0.0701,  0.1160,  0.1242, -0.0041, -0.1010, -0.0510,\n",
       "                       -0.0723, -0.0997,  0.0856, -0.1156, -0.0255, -0.0086,  0.0771,  0.1042,\n",
       "                       -0.1112, -0.0047]])),\n",
       "             ('deep.dense.bias', tensor([0.1124])),\n",
       "             ('dense.weight', tensor([[ 0.5110, -0.3250]])),\n",
       "             ('dense.bias', tensor([-0.3893]))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                                                                                                                                                                                                       \n",
    "import numpy                                                                                                                                                                                                      \n",
    "import torch                                                                                                                                                                                                      \n",
    "import torch.nn as nn                                                                                                                                                                                             \n",
    "import torch.nn.functional as F                                                                                                                                                                                   \n",
    "import torch.optim as optim                                                                                                                                                                                       \n",
    "from torch.autograd import Variable                                                                                                                                                                               \n",
    "from torch.nn.parameter import Parameter                                                                                                                                                                          \n",
    "                                                                                                                                                                                                                  \n",
    "                                                                                                                                                                                                                  \n",
    "class Toy(nn.Module):                                                                                                                                                                                             \n",
    "    def __init__(self):                                                                                                                                                                                           \n",
    "        super(Toy, self).__init__()                                                                                                                                                                               \n",
    "        self.embed = nn.Embedding(100000, 256, sparse=True)                                                                                                                                                       \n",
    "        self.lin = nn.Linear(256, 256)                                                                                                                                                                            \n",
    "    def forward(self, idx):                                                                                                                                                                                       \n",
    "        return self.lin(F.sigmoid(self.embed(idx)))                                                                                                                                                               \n",
    "                                                                                                                                                                                                                  \n",
    "                                                                                                                                                                                                                  \n",
    "toy = Toy().cuda()                                                                                                                                                                                                \n",
    "optimizer = optim.SparseAdam(toy.parameters(), lr=0.001)                                                                                                                                                          \n",
    "criterion = nn.CrossEntropyLoss().cuda()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAdam (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
