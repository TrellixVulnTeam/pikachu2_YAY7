{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, log_loss, mean_squared_error, mean_absolute_error\n",
    "import gezi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.random_normal([2, 8, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(2, 8, 3), dtype=float32, numpy=\n",
       "array([[[ 0.63228077,  0.86531305, -0.3053677 ],\n",
       "        [-0.6178    ,  1.2101597 , -0.26687023],\n",
       "        [-0.7250177 , -0.86864716, -1.5621979 ],\n",
       "        [-1.2312133 ,  1.1414009 , -0.84329027],\n",
       "        [ 0.5682497 ,  0.95293283, -1.3176906 ],\n",
       "        [ 1.3617997 , -0.00987865, -1.4242511 ],\n",
       "        [ 0.3111133 ,  0.8858375 , -0.29353368],\n",
       "        [-0.22367527, -0.53028625, -0.05714251]],\n",
       "\n",
       "       [[ 0.96788794, -0.67219263, -0.22908396],\n",
       "        [ 1.3660717 ,  1.0273248 , -0.9666571 ],\n",
       "        [ 1.4951528 ,  0.65344167,  1.7204219 ],\n",
       "        [ 0.844709  , -0.07005837, -0.00774324],\n",
       "        [-1.2686813 ,  0.89502805, -0.18682602],\n",
       "        [ 0.60661644, -1.1651388 , -1.7967056 ],\n",
       "        [-0.72723204,  0.14008093, -1.8052537 ],\n",
       "        [-0.78192294, -1.6477147 , -0.41716218]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids = tf.constant([[1, 2, 5, 3, 1, 3, 5, 5], [2, 2, 3, 3, 1, 1, 4, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7, shape=(2, 8), dtype=int32, numpy=\n",
       "array([[1, 2, 5, 3, 1, 3, 5, 5],\n",
       "       [2, 2, 3, 3, 1, 1, 4, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ids_ = tf.tile(tf.expand_dims(seg_ids, -1), [1, 1, melt.get_shape(data, -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=35, shape=(2, 8, 3), dtype=int32, numpy=\n",
       "array([[[1, 1, 1],\n",
       "        [2, 2, 2],\n",
       "        [5, 5, 5],\n",
       "        [3, 3, 3],\n",
       "        [1, 1, 1],\n",
       "        [3, 3, 3],\n",
       "        [5, 5, 5],\n",
       "        [5, 5, 5]],\n",
       "\n",
       "       [[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [3, 3, 3],\n",
       "        [3, 3, 3],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [4, 4, 4],\n",
       "        [4, 4, 4]]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_ids_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dimension(2), Dimension(8), Dimension(3)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(melt.get_shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = tf.zeros([melt.get_shape(data, 0), 6] + [melt.get_shape(data, -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=60, shape=(2, 6, 3), dtype=float32, numpy=\n",
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Inner dimensions of output shape must match inner dimensions of updates shape. Output: [3,2,6] updates: [3,2,8] [Op:TensorScatterAdd]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c13e25d8d213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_scatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_ids_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gezi/env/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtensor_scatter_add\u001b[0;34m(tensor, indices, updates, name)\u001b[0m\n\u001b[1;32m  10355\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10356\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10357\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10358\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10359\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/env/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [3,2,6] updates: [3,2,8] [Op:TensorScatterAdd]"
     ]
    }
   ],
   "source": [
    "tf.tensor_scatter_add(tf.transpose(ref, [2, 0, 1]), tf.transpose(seg_ids_, [2, 0, 1]), tf.transpose(data, [2, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,6,3] updates: [2,8,3] [Op:TensorScatterAdd]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-60345d26bd5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_scatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_ids_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gezi/env/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtensor_scatter_add\u001b[0;34m(tensor, indices, updates, name)\u001b[0m\n\u001b[1;32m  10355\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10356\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10357\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10358\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10359\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gezi/env/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [2,6,3] updates: [2,8,3] [Op:TensorScatterAdd]"
     ]
    }
   ],
   "source": [
    "tf.tensor_scatter_add(ref, seg_ids_, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=26, shape=(2, 6, 3), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 1.2005305 ,  1.8182459 , -1.6230583 ],\n",
       "        [-0.6178    ,  1.2101597 , -0.26687023],\n",
       "        [ 0.13058639,  1.1315223 , -2.2675414 ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.6375797 , -0.5130959 , -1.9128741 ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.66206485, -0.2701108 , -1.9835316 ],\n",
       "        [ 2.3339596 ,  0.35513216, -1.195741  ],\n",
       "        [ 2.3398619 ,  0.5833833 ,  1.7126787 ],\n",
       "        [-1.509155  , -1.5076338 , -2.222416  ],\n",
       "        [ 0.        ,  0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt.unsorted_segment_embs(data, seg_ids, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsorted_segment_sum_(data, segment_ids, num_segments):\n",
    "    \"\"\"\n",
    "    Computes the sum along segments of a tensor. Analogous to tf.unsorted_segment_sum.\n",
    "\n",
    "    :param data: A tensor whose segments are to be summed.\n",
    "    :param segment_ids: The segment indices tensor.\n",
    "    :param num_segments: The number of segments.\n",
    "    :return: A tensor of same data type as the data argument.\n",
    "    \"\"\"\n",
    "    segment_ids = torch.repeat_interleave(segment_ids.unsqueeze(-1), repeats=data.shape[-1], dim=-1)\n",
    "\n",
    "    shape = [data.shape[0], num_segments] + list(data.shape[2:])\n",
    "    print(shape, seg_ids.shape, data.shape)\n",
    "    tensor = torch.zeros(*shape).scatter_add(1, segment_ids, data)\n",
    "    # tensor = torch.zeros(*shape).cuda().scatter_add(1, segment_ids, data)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 1.2005,  1.8182, -1.6231],\n",
       "         [-0.6178,  1.2102, -0.2669],\n",
       "         [ 0.1306,  1.1315, -2.2675],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.6376, -0.5131, -1.9129]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.6621, -0.2701, -1.9835],\n",
       "         [ 2.3340,  0.3551, -1.1957],\n",
       "         [ 2.3399,  0.5834,  1.7127],\n",
       "         [-1.5092, -1.5076, -2.2224],\n",
       "         [ 0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lele.unsorted_segment_sum(torch.as_tensor(data.numpy()), torch.as_tensor(seg_ids.numpy()).long(), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 3] (2, 8) torch.Size([2, 8, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 1.2005,  1.8182, -1.6231],\n",
       "         [-0.6178,  1.2102, -0.2669],\n",
       "         [ 0.1306,  1.1315, -2.2675],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.6376, -0.5131, -1.9129]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.6621, -0.2701, -1.9835],\n",
       "         [ 2.3340,  0.3551, -1.1957],\n",
       "         [ 2.3399,  0.5834,  1.7127],\n",
       "         [-1.5092, -1.5076, -2.2224],\n",
       "         [ 0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsorted_segment_sum_(torch.as_tensor(data.numpy()), torch.as_tensor(seg_ids.numpy()).long(), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.constant([[0], [2]])\n",
    "updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]],\n",
    "                       [[5, 5, 5, 5], [6, 6, 6, 6],\n",
    "                        [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
    "tensor = tf.ones([4, 4, 4],dtype=tf.int32)\n",
    "updated = tf.tensor_scatter_nd_add(tensor, indices, updates)\n",
    "print(updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1., 2.], [3., 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tile(tf.expand_dims(x, -1), [1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.constant([[1., 2.], [3., 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.as_tensor(x_.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.repeat_interleave(y.unsqueeze(-1), 3, dim=-1)[:,:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [2, 2, 2],\n",
       "         [5, 5, 5],\n",
       "         [3, 3, 3],\n",
       "         [1, 1, 1],\n",
       "         [3, 3, 3],\n",
       "         [5, 5, 5],\n",
       "         [5, 5, 5]],\n",
       "\n",
       "        [[2, 2, 2],\n",
       "         [2, 2, 2],\n",
       "         [3, 3, 3],\n",
       "         [3, 3, 3],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [4, 4, 4],\n",
       "         [4, 4, 4]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(torch.as_tensor(seg_ids.numpy()).unsqueeze(-1), 3, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tf.constant([[4], [3], [1], [7]])\n",
    "updates = tf.constant([9, 10, 11, 12])\n",
    "tensor = tf.ones([8], dtype=tf.int32)\n",
    "updated = tf.tensor_scatter_nd_add(tensor, indices, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = 3, 4, 5\n",
    "memory = tf.ones([a, b, c])\n",
    "indices = tf.constant([[2], [0], [3]])\n",
    "updates = 10 * tf.reshape(tf.range(a * c, dtype=memory.dtype), [a, c])\n",
    "print(updates.numpy())\n",
    "# [[  0.  10.  20.  30.  40.]\n",
    "#  [ 50.  60.  70.  80.  90.]\n",
    "#  [100. 110. 120. 130. 140.]]\n",
    "\n",
    "# Make indices for first dimension\n",
    "ind_a = tf.range(tf.shape(indices, out_type=indices.dtype)[0])\n",
    "# Make full indices\n",
    "indices_2 = tf.concat([tf.expand_dims(ind_a, 1), indices], axis=1)\n",
    "# Scatter add\n",
    "out = tf.tensor_scatter_nd_add(memory, indices_2, updates)\n",
    "print(out.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('/home/gezi/tmp/rank/exps/video/v25/dlrm-active/infos/2020060723/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv('/home/gezi/tmp/rank/exps/video/v25/8/2020060723/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d2[d2.product_data=='sgsapp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d2[d2.abtestid.isin([4,5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d2.sort_values(['mid', 'impression_time', 'position']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.sort_values(['mid', 'impression_time', 'position']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d['article_page_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = d.merge(d2[['docid', 'impression_time', 'article_page_time']], on=['docid', 'impression_time'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[['mid', 'docid', 'position', 'impression_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2[['mid', 'docid', 'position', 'impression_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([d, d2.article_page_time], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[['mid', 'docid', 'position', 'impression_time', 'article_page_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2[['mid', 'docid', 'position', 'impression_time', 'article_page_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['page_time'] = ((d.impression_time - d.article_page_time) / 3600).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2['page_time'] = ((d2.impression_time - d2.article_page_time) / 3600).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.localtime(d.impression_time.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.page_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.page_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(d.duration != 0, d.pred_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(d2.duration != 0, d2.pred_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1 = d[d.page_time>720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(d_1.duration != 0, d_1.pred_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_1 =  d2[d2.page_time>720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(d2_1.duration != 0, d2_1.pred_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2 = d[d.page_time<240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_2 = d2[d2.page_time>240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(d_2.duration != 0, d_2.pred_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(d2_2.duration != 0, d2_2.pred_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.page_time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.metrics.group_auc(d.duration != 0, d.pred_click, d.mid + '\\t' + d.impression_time.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.metrics.group_auc(d2.duration != 0, d2.pred_click, d2.mid + '\\t' + d2.impression_time.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3 = d[d.page_time > 720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_3 = d2[d2.page_time > 720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_auc(d):\n",
    "  return gezi.metrics.group_auc((d.duration != 0).values, d.pred_click.values, (d.mid + '\\t' + d.impression_time.astype(str)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_auc(d_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_auc(d2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['num_histories'] = d.num_tw_histories + d.num_vd_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.concat([d2, d.num_histories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3 = d[d.num_histories>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_3 = d2[d2.num_histories>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_auc(d_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_auc(d2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
