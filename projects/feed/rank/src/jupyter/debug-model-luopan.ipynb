{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow_version: 1.14.0\n",
      "torch_version: 1.3.1+cu100\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pymp\n",
    "from multiprocessing import Manager, cpu_count \n",
    "import sys\n",
    "import os\n",
    "import glob \n",
    "import gezi\n",
    "from gezi import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "# import cudf\n",
    "# import dask.dataframe as dd\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('f', None, '')\n",
    "import melt\n",
    "\n",
    "from plotly.graph_objs import Scatter,Layout\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#setting offilne\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gezi/mine/pikachu/utils/melt/util.py:432: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-11 21:05:00 0:00:00 os.environ['CUDA_VISIBLE_DEVICES'] -1\n",
      "2020-01-11 21:05:00 0:00:00 os.environ['CUDA_VISIBLE_DEVICES'] -1\n",
      "2020-01-11 21:05:00 0:00:00 Tf dataset and Tf model train in Graph mode, support Horovod, keras False\n",
      "2020-01-11 21:05:00 0:00:00 seed 70293\n",
      "2020-01-11 21:05:00 0:00:00 log_level: 20\n",
      "2020-01-11 21:05:00 0:00:00 valid_interval_epochs: 0.0\n",
      "2020-01-11 21:05:00 0:00:00 buffer_size:0\n",
      "2020-01-11 21:05:00 0:00:00 batch_size: 32 eval_batch_size: 32 batch_size_per_gpu: 32 num_gpus: 1 horovod: False\n",
      "2020-01-11 21:05:00 0:00:00 model_dir /tmp/melt log_dir /tmp/melt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/odin/publicData/CloudS/chenghuige/rank/data/tuwen_hour_sgsapp_v1/models/8/2020011013\n",
      "WARNING:tensorflow:From /home/gezi/env/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /search/odin/publicData/CloudS/chenghuige/rank/data/tuwen_hour_sgsapp_v1/models/8/2020011013/model.ckpt-2020011013-1.00-7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-11 21:05:59 0:00:58 Restoring using: 58.5492000579834\n"
     ]
    }
   ],
   "source": [
    "# 载入模型\n",
    "model_hour = '2020010310'\n",
    "model_hour = '2020010316'\n",
    "model_root = '/search/odin/publicData/CloudS/baili/new_rank/data/tuwen_hour_sgsapp_v1/models/16'\n",
    "model_hour = '2020011013'\n",
    "abtest = 8\n",
    "model_root = f'/home/gezi/tmp/rank/data/tuwen_hour_sgsapp_v1/models/{abtest}'\n",
    "FLAGS(sys.argv)\n",
    "melt.init(tf.Graph())\n",
    "sess = melt.get_session()\n",
    "model_path = os.path.realpath(f'{model_root}/{model_hour}')\n",
    "print(model_path)\n",
    "predictor = melt.Predictor(sess=sess, model_dir=model_path)\n",
    "assert predictor.graph.get_collection('index_feed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = ['tuwen', 'video']\n",
    "head = 'mid,docid,dur,pred,abid,ori_lr_score,lr_score,show_time,position,video_time,impression_time, \\\n",
    "        interests,rea,pred_click,pred_dur,product_data,distribution'\n",
    "# mid = 'e5e9b96d57c21de54eecf437e2b4f4c3f1c7de66b950'\n",
    "hour = '2020011015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abtest = 16\n",
    "def deal(df):\n",
    "  df.hour = df.hour.astype(str)\n",
    "  df = df.groupby(['abtest', 'hour'], as_index=False).last()\n",
    "  df = df.sort_values(by=['hour'])\n",
    "  df = df.drop_duplicates()\n",
    "  df.hour = pd.to_datetime(df.hour, format='%Y%m%d%H')\n",
    "  return df\n",
    "\n",
    "# 遍历infos路径获取scores信息\n",
    "def gen_df(mark, start_time=None, end_time=None):\n",
    "  #root = f'/search/odin/baili/video_data/data/{mark}_hour_sgsapp_v1/infos/16'  \n",
    "  root = f'/search/odin/publicData/CloudS/rank/infos/{mark}/{abtest}'\n",
    "  dfs = Manager().dict()\n",
    "  files = glob.glob(f'{root}/*/scores')\n",
    "  ps = min(len(files), cpu_count())\n",
    "#   with pymp.Parallel(ps) as p:\n",
    "#     for i in tqdm(p.range(len(files))):\n",
    "  for i in tqdm(range(len(files))):\n",
    "    file = files[i]\n",
    "    hour_ = os.path.basename(os.path.dirname(file))\n",
    "#     print(hour)\n",
    "    if not hour_.startswith(hour):\n",
    "      continue\n",
    "    if not gezi.non_empty(file):\n",
    "      continue\n",
    "    df = pd.read_csv(file, sep='\\t', header=None)\n",
    "    df.columns = head.split(',')[:len(df.columns)]\n",
    "  #       df = df[df.mid==mid]\n",
    "    if len(df):\n",
    "      df = df.assign(hour=hour_)\n",
    "      dfs[hour] = df\n",
    "  print('num_hours_match:', len(dfs))\n",
    "  df = pd.concat(dfs.values())\n",
    "  df.name = mark\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:03<00:00, 52.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_hours_match: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>video_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>632</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>758</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>652</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>603</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>624</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918950</th>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919414</th>\n",
       "      <td>678</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919420</th>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919421</th>\n",
       "      <td>663</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919835</th>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  video_time\n",
       "107     632         633\n",
       "1542    758         771\n",
       "2005    652         652\n",
       "4687    603         603\n",
       "5315    624         624\n",
       "...     ...         ...\n",
       "918950  621         621\n",
       "919414  678         678\n",
       "919420  831         831\n",
       "919421  663         663\n",
       "919835  894         894\n",
       "\n",
       "[1473 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tuwen = gen_df('tuwen')\n",
    "df_video = gen_df('video')\n",
    "df_video[df_video.dur > 600][['dur',  'video_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tuwen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-65a4e1c6ef9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tuwen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mori_lr_score\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct_data\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sgsapp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# df = df[df.abid == abtest]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# df[df.mid == '0002864821039187368']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_tuwen' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_tuwen\n",
    "df = df[df.ori_lr_score != -1.]\n",
    "df = df[df.product_data == 'sgsapp']\n",
    "# df = df[df.abid == abtest]\n",
    "# df[df.mid == '0002864821039187368']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_root = '/search/odin/publicData/CloudS/baili/rank/sgsapp/data/tuwen_hour_sgsapp_v1/tfrecords/'\n",
    "tfrecord_dir = os.path.realpath(f'{tfrecord_root}/{hour}')\n",
    "files = gezi.list_files(tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.feed.rank.src.tfrecord_dataset import Dataset\n",
    "from projects.feed.rank.src import util\n",
    "num_records_file = os.path.join(tfrecord_dir, \"num_records.txt\")\n",
    "print(num_records_file)\n",
    "total = melt.get_num_records(files) if not os.path.exists(num_records_file) else gezi.read_int_from(num_records_file)\n",
    "print('total', total, file=sys.stderr)\n",
    "batch_size = 512\n",
    "l = []\n",
    "with sess.graph.as_default():\n",
    "  # if not infer very slow just use cpu to do it.. so we can train more models parallel\n",
    "  dataset = Dataset('valid')\n",
    "  iter = dataset.make_batch(batch_size=batch_size, filenames=files, repeat=False)\n",
    "  op = iter.get_next()\n",
    "\n",
    "  print('---batch_size', dataset.batch_size, FLAGS.batch_size, melt.batch_size(), file=sys.stderr)  \n",
    "\n",
    "  num_steps = -int(-total // batch_size)\n",
    "  print('----num_steps', num_steps, file=sys.stderr) \n",
    "  try:\n",
    "    for _ in tqdm(range(num_steps), total=num_steps):\n",
    "      x, y = sess.run(op)\n",
    "      mids = np.asarray([m.decode() for m in x['mid']])\n",
    "      docids = np.asarray([m.decode() for m in x['docid']])\n",
    "      x['mid'] = mids\n",
    "      x['docid'] = docids\n",
    "      l += [x]\n",
    "  except Exception:\n",
    "    print('abc')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "l2 = copy.deepcopy(l)\n",
    "# mid = '0005860595047198898'\n",
    "# docid = '20102e0l3KDdu7'\n",
    "mid = 'fffc868062043258335'\n",
    "docid = 'open_doc_prod16543897'\n",
    "for i in tqdm(range(len(l2))):\n",
    "  filter_flag = l2[i]['mid'] == mid\n",
    "  filter_flag *= l2[i]['docid'] == docid\n",
    "  for key in l2[i]:\n",
    "    try:\n",
    "      l2[i][key] = l2[i][key][filter_flag]\n",
    "    except Exception:\n",
    "      pass\n",
    "l2 = [x for x in l2 if len(x['mid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "  feed_dict = {\n",
    "                predictor.graph.get_collection('index_feed')[0]: x['index'],\n",
    "                predictor.graph.get_collection('value_feed')[0]: x['value'],\n",
    "                predictor.graph.get_collection('field_feed')[0]: x['field'],\n",
    "                predictor.graph.get_collection('uid_feed')[0]: x['uid'],\n",
    "                predictor.graph.get_collection('did_feed')[0]: x['did'],\n",
    "                predictor.graph.get_collection('doc_idx_feed')[0]: x['history'],\n",
    "              } \n",
    "  feed_dict.update({\n",
    "                  predictor.graph.get_collection('time_interval_feed')[0]: x['time_interval'].reshape(-1, 1),\n",
    "                  predictor.graph.get_collection('time_weekday_feed')[0]: x['time_weekday'].reshape(-1, 1),\n",
    "                  predictor.graph.get_collection('timespan_interval_feed')[0]: x['timespan_interval'].reshape(-1, 1),             \n",
    "#                   predictor.graph.get_collection('product_feed')[0]: product_.reshape(-1, 1)\n",
    "        })\n",
    "#   return predictor.predict(['pred', 'pred_click', 'pred_dur'], feed_dict)\n",
    "  return predictor.predict('pred', feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(l2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = copy.deepcopy(l2[0])\n",
    "# x['value'][0] = np.ones_like(x['value'][0])\n",
    "predict(x)\n",
    "x['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['value'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(x, fields):\n",
    "  if isinstance(fields, str):\n",
    "    fields = set(map(int, fields.split(',')))\n",
    "  else:\n",
    "    fields = set(fields)\n",
    "  for i in range(len(x['field'])):\n",
    "    flag = np.asarray([float(x !=0 and x not in fields) for x in x['field'][i]])\n",
    "    x['value'][i] *= flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = open('/home/gezi/mine/pikachu/projects/feed/rank/src/conf/tuwen/fields.txt').readlines()\n",
    "field_names = [f'{i+1}:{x.strip()}' for i, x in enumerate(field_names)]\n",
    "field_names.insert(0, '0:None')\n",
    "# field_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for x in l2:\n",
    "  pred = predict(x)\n",
    "  res.append([x['docid'][0], x['impression_time'][0], x['position'][0], pred[0][0][0]])\n",
    "df = pd.DataFrame.from_dict(res)\n",
    "df.columns=['docid', 'impression_time', 'position', 'pred']\n",
    "df.sort_values('pred', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = []\n",
    "# l2 = copy.deepcopy(l)\n",
    "# for x in l2:\n",
    "#   mask(x, [47,53,89,84,55])\n",
    "#   pred = predict(x)\n",
    "#   res.append([x['docid'][0], x['impression_time'][0], x['position'][0], pred[0][0][0]])\n",
    "# df = pd.DataFrame.from_dict(res)\n",
    "# df.columns=['docid', 'impression_time', 'position', 'pred']\n",
    "# df.sort_values('pred', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(91):\n",
    "  x = copy.deepcopy(l2[0])\n",
    "  mask(x, [i])\n",
    "  res.append([field_names[i], predict(x)[0][0][0]])\n",
    "df = pd.DataFrame.from_dict(res)\n",
    "df.columns=['field', 'pred']\n",
    "df.sort_values('pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pred > 0.358][df.pred < 0.359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
